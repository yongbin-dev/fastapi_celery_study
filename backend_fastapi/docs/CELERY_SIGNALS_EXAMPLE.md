# Celery ì‹ í˜¸ë¥¼ í†µí•œ DB ì €ì¥ ì˜ˆì œ

í˜„ì¬ ìŠ¤í‚¤ë§ˆì— ë§ì¶°ì„œ Celery ì‹ í˜¸ë¥¼ í†µí•´ ìë™ìœ¼ë¡œ DBì— ì‘ì—… ì •ë³´ë¥¼ ì €ì¥í•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

## ğŸš€ ì£¼ìš” ê¸°ëŠ¥

### ìë™ ì¶”ì ë˜ëŠ” ì •ë³´ë“¤

1. **TaskLog**: ëª¨ë“  Celery ì‘ì—…ì˜ ìƒëª…ì£¼ê¸°
2. **TaskMetadata**: ì‘ì—… ë©”íƒ€ë°ì´í„° (í, ìš°ì„ ìˆœìœ„ ë“±)
3. **TaskExecutionHistory**: ê° ì‹œë„ë³„ ì‹¤í–‰ ê¸°ë¡
4. **TaskResult**: ì‘ì—… ê²°ê³¼ (ì„±ê³µ/ì‹¤íŒ¨)
5. **WorkerStatus**: ì›Œì»¤ ìƒíƒœ ë° í†µê³„
6. **QueueStats**: í í†µê³„ (ì£¼ê¸°ì  ìˆ˜ì§‘)

### ì²˜ë¦¬ë˜ëŠ” Celery ì‹ í˜¸ë“¤

- `before_task_publish`: ì‘ì—… ë°œí–‰ ì‹œ â†’ TaskLog, TaskMetadata ìƒì„±
- `task_prerun`: ì‘ì—… ì‹œì‘ ì‹œ â†’ TaskLog ìƒíƒœ ì—…ë°ì´íŠ¸, TaskExecutionHistory ìƒì„±
- `task_success`: ì‘ì—… ì„±ê³µ ì‹œ â†’ TaskLog, TaskResult, TaskExecutionHistory ì—…ë°ì´íŠ¸
- `task_failure`: ì‘ì—… ì‹¤íŒ¨ ì‹œ â†’ ì—ëŸ¬ ì •ë³´ ì €ì¥
- `task_retry`: ì‘ì—… ì¬ì‹œë„ ì‹œ â†’ ì¬ì‹œë„ ê¸°ë¡
- `task_revoked`: ì‘ì—… ì·¨ì†Œ ì‹œ â†’ ì·¨ì†Œ ìƒíƒœ ì €ì¥
- `worker_ready`: ì›Œì»¤ ì‹œì‘ ì‹œ â†’ WorkerStatus ìƒì„±/ì—…ë°ì´íŠ¸
- `worker_shutdown`: ì›Œì»¤ ì¢…ë£Œ ì‹œ â†’ WorkerStatus ì—…ë°ì´íŠ¸
- `heartbeat_sent`: ì›Œì»¤ í•˜íŠ¸ë¹„íŠ¸ â†’ WorkerStatus ê°±ì‹ 

## ğŸ“‹ ì‚¬ìš© ë°©ë²•

### 1. ê¸°ë³¸ ì„¤ì •

Celery ì•±ì´ ì‹œì‘ë  ë•Œ ìë™ìœ¼ë¡œ ì‹ í˜¸ê°€ ë“±ë¡ë©ë‹ˆë‹¤:

```python
# app/core/celery_app.pyì—ì„œ ìë™ import
from . import celery_signals
```

### 2. í…ŒìŠ¤íŠ¸ ì‹¤í–‰

```bash
# 1. ì›Œì»¤ ì‹œì‘
python -m celery -A app.core.celery_app worker --loglevel=info

# 2. ë³„ë„ í„°ë¯¸ë„ì—ì„œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
python test_celery_signals.py
```

### 3. ì‘ì—… ì •ì˜ ì˜ˆì œ

```python
from app.core.celery_app import celery_app

@celery_app.task(bind=True, name='my_custom_task')
def my_custom_task(self, data):
    """ì‚¬ìš©ì ì •ì˜ ì‘ì—… - ìë™ìœ¼ë¡œ DBì— ê¸°ë¡ë©ë‹ˆë‹¤"""
    # ì‘ì—… ë¡œì§
    result = process_data(data)
    
    # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ (ì„ íƒì‚¬í•­)
    self.update_state(
        state='PROGRESS',
        meta={'current': 50, 'total': 100}
    )
    
    return result

# ì‘ì—… ì‹¤í–‰
task = my_custom_task.delay({"key": "value"})
```

### 4. ì¬ì‹œë„ ê°€ëŠ¥í•œ ì‘ì—…

```python
@celery_app.task(
    bind=True, 
    name='retry_task',
    autoretry_for=(Exception,),
    retry_kwargs={'max_retries': 3, 'countdown': 5}
)
def retry_task(self, data):
    """ìë™ ì¬ì‹œë„ ì‘ì—…"""
    if random.random() < 0.7:  # 70% í™•ë¥ ë¡œ ì‹¤íŒ¨
        raise Exception("ì¼ì‹œì  ì˜¤ë¥˜")
    
    return {"status": "success"}
```

## ğŸ“Š DBì—ì„œ í™•ì¸í•  ìˆ˜ ìˆëŠ” ì •ë³´

### TaskLog í…Œì´ë¸”
```sql
SELECT 
    task_id,
    task_name,
    status,
    started_at,
    completed_at,
    retries,
    (completed_at - started_at) as duration
FROM task_logs 
ORDER BY created_at DESC 
LIMIT 10;
```

### WorkerStatus í…Œì´ë¸”
```sql
SELECT 
    worker_name,
    status,
    active_tasks,
    processed_tasks,
    failed_tasks,
    (processed_tasks - failed_tasks) * 100.0 / processed_tasks as success_rate
FROM worker_status;
```

### TaskExecutionHistory í…Œì´ë¸”
```sql
SELECT 
    t.task_name,
    h.attempt_number,
    h.status,
    h.started_at,
    h.completed_at,
    h.error_message
FROM task_execution_history h
JOIN task_logs t ON h.task_id = t.id
ORDER BY h.started_at DESC;
```

## ğŸ”§ ê³ ê¸‰ ì‚¬ìš©ë²•

### 1. ì‚¬ìš©ì ì •ì˜ ë©”íƒ€ë°ì´í„° ì¶”ê°€

```python
@celery_app.task(bind=True)
def task_with_metadata(self, data, user_id=None):
    """ì‚¬ìš©ì ì •ì˜ ë©”íƒ€ë°ì´í„°ê°€ ìˆëŠ” ì‘ì—…"""
    # ë©”íƒ€ë°ì´í„°ëŠ” TaskMetadata í…Œì´ë¸”ì— ìë™ ì €ì¥ë¨
    return process_user_data(data, user_id)

# ì‚¬ìš©
task = task_with_metadata.apply_async(
    args=[data],
    kwargs={'user_id': 123},
    priority=5,  # ìš°ì„ ìˆœìœ„
    eta=datetime.now() + timedelta(minutes=5)  # ì‹¤í–‰ ì‹œê°„
)
```

### 2. í†µê³„ ì •ë³´ ì¡°íšŒ

```python
from app.core.celery_signals import get_task_statistics
from app.core.database import SyncSessionLocal

session = SyncSessionLocal()
stats = get_task_statistics(session)
print(stats)  # {'SUCCESS': 45, 'FAILURE': 5, 'PENDING': 2}
session.close()
```

### 3. ì˜¤ë˜ëœ ë ˆì½”ë“œ ì •ë¦¬

```python
from app.core.celery_signals import cleanup_old_records
from app.core.database import SyncSessionLocal

session = SyncSessionLocal()
deleted_count = cleanup_old_records(session, days=30)
print(f"ì •ë¦¬ëœ ë ˆì½”ë“œ: {deleted_count}ê°œ")
session.close()
```

## ğŸ¯ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§

### 1. Flower ëŒ€ì‹œë³´ë“œ
```bash
python -m celery -A app.core.celery_app flower --port=5555
```
ë¸Œë¼ìš°ì €ì—ì„œ http://localhost:5555 ì ‘ì†

### 2. í”„ë¡œê·¸ë˜ë° ë°©ì‹ ëª¨ë‹ˆí„°ë§

```python
from app.core.database import SyncSessionLocal
from app.models import TaskLog, WorkerStatus

def get_realtime_status():
    session = SyncSessionLocal()
    try:
        # ì‹¤í–‰ ì¤‘ì¸ ì‘ì—…
        running_tasks = session.query(TaskLog).filter_by(status='STARTED').all()
        
        # ì˜¨ë¼ì¸ ì›Œì»¤
        online_workers = session.query(WorkerStatus).filter_by(status='ONLINE').all()
        
        return {
            'running_tasks': len(running_tasks),
            'online_workers': len(online_workers),
            'tasks': [{'id': t.task_id, 'name': t.task_name} for t in running_tasks]
        }
    finally:
        session.close()
```

## âš¡ ì„±ëŠ¥ ìµœì í™”

### 1. ë°°ì¹˜ ì²˜ë¦¬ë¥¼ ìœ„í•œ ì‹ í˜¸ ë¹„í™œì„±í™” (ì„ íƒì‚¬í•­)

```python
from celery import group

# ëŒ€ëŸ‰ ì‘ì—… ì‹œ ì‹ í˜¸ ì˜¤ë²„í—¤ë“œ ë°©ì§€
@celery_app.task(bind=True, track_started=False)
def batch_task(self, data):
    """ë°°ì¹˜ ì²˜ë¦¬ìš© ì‘ì—… (ì‹œì‘ ì‹ í˜¸ ë¹„í™œì„±í™”)"""
    return process_batch(data)

# ê·¸ë£¹ìœ¼ë¡œ ì‹¤í–‰
job = group(batch_task.s(item) for item in large_dataset)
result = job.apply_async()
```

### 2. ì¤‘ìš”í•œ ì‘ì—…ë§Œ ì¶”ì 

```python
@celery_app.task(bind=True, name='critical_task')
def critical_task(self, data):
    """ì¤‘ìš”í•œ ì‘ì—… - ìƒì„¸ ì¶”ì """
    return process_critical_data(data)

@celery_app.task(bind=True, name='simple_task', track_started=False)
def simple_task(self, data):
    """ë‹¨ìˆœí•œ ì‘ì—… - ìµœì†Œ ì¶”ì """
    return process_simple_data(data)
```

## ğŸ› íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### 1. ì‹ í˜¸ê°€ ì‘ë™í•˜ì§€ ì•ŠëŠ” ê²½ìš°

```python
# celery_app.pyì—ì„œ import ìˆœì„œ í™•ì¸
from . import celery_signals  # ì´ê²Œ ìµœìƒë‹¨ì— ìˆì–´ì•¼ í•¨
```

### 2. DB ì—°ê²° ì˜¤ë¥˜

```python
# celery_signals.pyì˜ get_db_session() í•¨ìˆ˜ í™•ì¸
# ë¡œê·¸ì—ì„œ "DB ì„¸ì…˜ ìƒì„± ì‹¤íŒ¨" ë©”ì‹œì§€ í™•ì¸
```

### 3. ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¦ê°€

```python
# ì£¼ê¸°ì ìœ¼ë¡œ ì˜¤ë˜ëœ ë ˆì½”ë“œ ì •ë¦¬
from app.core.celery_signals import cleanup_old_records

# crontabìœ¼ë¡œ ì£¼ê¸°ì  ì‹¤í–‰ ê¶Œì¥
# 0 2 * * * cd /path/to/project && python -c "from app.core.celery_signals import cleanup_old_records; from app.core.database import SyncSessionLocal; session = SyncSessionLocal(); cleanup_old_records(session, 30); session.close()"
```

## ğŸ“ˆ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ êµ¬ì¶•

ì‹¤ì œ í”„ë¡œë•ì…˜ì—ì„œëŠ” ì´ ë°ì´í„°ë¥¼ í™œìš©í•´ Grafanaë‚˜ ì»¤ìŠ¤í…€ ëŒ€ì‹œë³´ë“œë¥¼ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```python
# API ì—”ë“œí¬ì¸íŠ¸ ì˜ˆì œ
from fastapi import APIRouter
from app.core.database import SyncSessionLocal
from app.models import TaskLog, WorkerStatus

router = APIRouter()

@router.get("/task-stats")
def get_task_stats():
    session = SyncSessionLocal()
    try:
        stats = session.query(TaskLog.status, func.count(TaskLog.id))\
            .group_by(TaskLog.status).all()
        return {status: count for status, count in stats}
    finally:
        session.close()

@router.get("/worker-status")
def get_worker_status():
    session = SyncSessionLocal()
    try:
        workers = session.query(WorkerStatus).all()
        return [worker.to_dict() for worker in workers]
    finally:
        session.close()
```

ì´ì œ ëª¨ë“  Celery ì‘ì—…ì´ ìë™ìœ¼ë¡œ DBì— ê¸°ë¡ë˜ê³  ì¶”ì ë©ë‹ˆë‹¤! ğŸ‰