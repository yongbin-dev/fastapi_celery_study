# tests/test_stress_chain.py

import asyncio
import os
import pytest
import pytest_asyncio
from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession
from sqlalchemy.orm import sessionmaker

from app.config import settings
from app.models.base import Base
from app.api.v1.services.pipeline_service import PipelineService
from app.api.v1.services.redis_service import RedisPipelineStatusManager
from app.schemas.pipeline import AIPipelineRequest
from app.api.v1.crud.async_crud.chain_execution import (
    chain_execution as chain_execution_crud,
)

# .env íŒŒì¼ì˜ DATABASE_URLì„ ì‚¬ìš©í•˜ë„ë¡ ì„¤ì •
ASYNC_SQLALCHEMY_DATABASE_URL = settings.DATABASE_URL

# í…ŒìŠ¤íŠ¸ìš© ë¹„ë™ê¸° in-memory SQLite ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •                                                                                                                                                                                                      â”‚
# --- 3. ë°ì´í„° ì‚­ì œ í•¨ìˆ˜ ---


@pytest_asyncio.fixture(scope="function")
async def async_engine():
    """í…ŒìŠ¤íŠ¸ìš© ë¹„ë™ê¸° ì—”ì§„ ìƒì„± (í•¨ìˆ˜ ìŠ¤ì½”í”„)"""
    engine = create_async_engine(ASYNC_SQLALCHEMY_DATABASE_URL, echo=False)

    async with engine.begin() as conn:
        await conn.run_sync(Base.metadata.create_all)
        # print("--- ëª¨ë“  í…Œì´ë¸”ì˜ ë°ì´í„° ì‚­ì œ ì‹œì‘ ---")
    yield engine

    # async with engine.begin() as conn:
    #     print("--- ëª¨ë“  í…Œì´ë¸”ì˜ ë°ì´í„° ì‚­ì œ ì‹œì‘ ---")
    #     for table in reversed(Base.metadata.sorted_tables):
    #         print(f"Deleting data from table: {table.name}")
    #         await conn.execute(table.delete())
    #     print("--- ëª¨ë“  í…Œì´ë¸”ì˜ ë°ì´í„° ì‚­ì œ ì™„ë£Œ ---")

    await engine.dispose()


@pytest_asyncio.fixture
async def session_maker(async_engine):
    """ë¹„ë™ê¸° ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜ ë©”ì´ì»¤ fixture"""
    return sessionmaker(bind=async_engine, class_=AsyncSession, expire_on_commit=False)


@pytest.mark.asyncio
async def test_run_1000_chains_concurrently(session_maker, num_chains):
    """ì§€ì •ëœ ê°œìˆ˜ì˜ ì²´ì¸ì„ ë™ì‹œì— ì‹¤í–‰í•˜ëŠ” ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸

    ì‚¬ìš© ë°©ë²•:
    1. ëª…ë ¹í–‰ ì˜µì…˜: pytest --num-chains=1000 tests/test_stress_chain.py::test_run_1000_chains_concurrently
    2. í™˜ê²½ë³€ìˆ˜: TEST_NUM_CHAINS=1000 pytest tests/test_stress_chain.py::test_run_1000_chains_concurrently
    3. ê¸°ë³¸ê°’: pytest tests/test_stress_chain.py::test_run_1000_chains_concurrently (100ê°œ)
    """
    # given
    print(f"\nğŸš€ {num_chains}ê°œì˜ ì²´ì¸ìœ¼ë¡œ ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    redis_manager = RedisPipelineStatusManager()

    # when
    requests = [
        AIPipelineRequest(
            text=f"Stress test message {i}",
            options={"param": "value"},
            priority=1,
            callback_url="http://localhost/callback",
        )
        for i in range(num_chains)
    ]

    async def run_single_pipeline(request: AIPipelineRequest):
        """ê° íŒŒì´í”„ë¼ì¸ì„ ë…ë¦½ì ì¸ ì„¸ì…˜ì—ì„œ ì‹¤í–‰í•˜ëŠ” í—¬í¼ í•¨ìˆ˜"""
        async with session_maker() as db_session:
            pipeline_service = PipelineService()
            return await pipeline_service.create_ai_pipeline(
                db=db_session, redis_service=redis_manager, request=request
            )

    tasks = [run_single_pipeline(req) for req in requests]

    # asyncio.gatherë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë“  íŒŒì´í”„ë¼ì¸ ìƒì„± ì‘ì—…ì„ ë™ì‹œì— ì‹¤í–‰
    results = await asyncio.gather(*tasks, return_exceptions=True)

    # then
    success_count = sum(1 for r in results if not isinstance(r, Exception))
    failure_count = len(results) - success_count

    print(f"Total chains attempted: {num_chains}")
    print(f"Successful creations: {success_count}")
    print(f"Failed creations: {failure_count}")

    for i, result in enumerate(results):
        if isinstance(result, Exception):
            print(f"Error for task {i}: {result}")

    # ëª¨ë“  ìš”ì²­ì´ ì„±ê³µì ìœ¼ë¡œ ì²˜ë¦¬ë˜ì—ˆëŠ”ì§€ í™•ì¸
    assert success_count == num_chains, f"{failure_count} chains failed to create."

    # ë°ì´í„°ë² ì´ìŠ¤ì— ì‹¤ì œë¡œ ë ˆì½”ë“œê°€ ìƒì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸
    async with session_maker() as session:
        all_chains = await chain_execution_crud.get_all(db=session)
        assert len(all_chains) == num_chains
