# celery_signals.py
import json
from datetime import timedelta , datetime
from sqlalchemy.orm import Session
from celery.signals import (
    task_prerun,
    task_success,
    task_failure,
    task_retry,
    task_revoked,
    worker_ready,
    worker_shutdown,
    heartbeat_sent,
    before_task_publish
)
from sqlalchemy.exc import SQLAlchemyError

from app.core.database import get_db_manager
from app.core.logging import get_logger
from app.models import (
    TaskLog, QueueStats
)
from app.api.v1.crud import (
    chain_execution as chain_execution_crud,
    task_log as task_log_crud,
    task_metadata as task_metadata_crud,
    task_execution_history as task_execution_history_crud
)

# ë¡œê±° ì„¤ì •
logger = get_logger(__name__)


def safe_json_dumps(data):
    """ì•ˆì „í•œ JSON ì§ë ¬í™”"""
    try:
        return json.dumps(data, ensure_ascii=False)
    except (TypeError, ValueError):
        return json.dumps(str(data))


def get_worker_name(sender=None):
    """ì•ˆì „í•˜ê²Œ ì›Œì»¤ ì´ë¦„ ê°€ì ¸ì˜¤ê¸°"""
    # ë‹¤ì–‘í•œ ê²½ë¡œë¡œ hostname ì‹œë„
    if hasattr(sender, 'hostname'):
        return sender.hostname
    elif hasattr(sender, 'consumer') and hasattr(sender.consumer, 'hostname'):
        return sender.consumer.hostname
    elif hasattr(sender, 'request') and hasattr(sender.request, 'hostname'):
        return sender.request.hostname
    else:
        # ë§ˆì§€ë§‰ ëŒ€ì•ˆ: ì‹œìŠ¤í…œ hostname ì‚¬ìš©
        import socket
        return f"celery@{socket.gethostname()}"

def get_chain_id_from_args(args):
    """task argsì—ì„œ chain_id ì¶”ì¶œ"""

    if args and len(args) > 0:
        # args[0]ì´ chain_idì¸ ê²½ìš° (UUID ë¬¸ìì—´)
        chain_id_str = str(args[0])
        if len(chain_id_str) == 36 and chain_id_str.count('-') == 4:  # UUID í˜•íƒœ í™•ì¸
            return chain_id_str
    return None


def get_chain_id_from_kwargs(kwargs):
    """task kwargsì—ì„œ chain_id ì¶”ì¶œ"""
    return kwargs.get('chain_id') if kwargs else None
    


def extract_stage_number(task_name):
    """task_nameì—ì„œ stage ë²ˆí˜¸ ì¶”ì¶œ (ì˜ˆ: app.tasks.stage1_preprocessing -> 1)"""

    if 'stage' in task_name:
        import re
        match = re.search(r'stage(\d+)', task_name)
        if match:
            return int(match.group(1))
    return None


# ì‘ì—… ê´€ë ¨ ì‹ í˜¸ ì²˜ë¦¬

@before_task_publish.connect
def task_publish_handler(sender=None, headers=None, body=None, properties=None, **kwargs):
    """ì‘ì—… ë°œí–‰ ì „ ì²˜ë¦¬"""
    logger.info(f"ğŸš€ SIGNAL: before_task_publish ìˆ˜ì‹  - sender: {sender}")
    # ë™ê¸° ì„¸ì…˜ ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €ë¥¼ ì‚¬ìš©í•˜ì—¬ ì„¸ì…˜ ê´€ë¦¬
    with get_db_manager().get_sync_session() as session:
        if not session:
            logger.error("âŒ DB ì„¸ì…˜ ìƒì„± ì‹¤íŒ¨ - before_task_publish")
            return

        try:
            # bodyì—ì„œ task ì •ë³´ ì¶”ì¶œ
            if body:
                task_name = body[0] if isinstance(body, (list, tuple)) and len(body) > 0 else None
                task_args = body[1] if isinstance(body, (list, tuple)) and len(body) > 1 else []
                task_kwargs = body[2] if isinstance(body, (list, tuple)) and len(body) > 2 else {}

                # Pipeline taskì¸ì§€ í™•ì¸
                if task_name and 'stage' in task_name:
                    chain_id = get_chain_id_from_args(task_args) or get_chain_id_from_kwargs(task_kwargs)
                    if chain_id:
                        logger.info(f"Pipeline task ë°œí–‰: {task_name}, chain_id: {chain_id}")

                        # ChainExecutionì´ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ìƒì„±
                        existing_chain = chain_execution_crud.get_by_chain_id(session, chain_id=chain_id)
                        if not existing_chain:
                            chain_execution_crud.create_chain_execution(
                                session,
                                chain_id=chain_id,
                                chain_name="pipeline_workflow",
                                total_tasks=4,
                                initiated_by="system"
                            )
                            logger.info(f"ìƒˆ ChainExecution ìƒì„±: {chain_id}")

        except Exception as e:
            logger.error(f"task_publish_handler ì˜¤ë¥˜: {e}",exc_info=True )
            


@task_prerun.connect
def task_prerun_handler(task_id=None, task=None, args=None, kwargs=None, **kwds):
    """ì‘ì—… ì‹¤í–‰ ì „ ì²˜ë¦¬"""
    logger.info(f"ğŸƒ SIGNAL: task_prerun ìˆ˜ì‹  - task_id: {task_id}")
    with get_db_manager().get_sync_session() as session:
        if not session:
            logger.error("âŒ DB ì„¸ì…˜ ìƒì„± ì‹¤íŒ¨ - task_prerun")
            return

        try:
            # TaskLog ìƒì„± ë˜ëŠ” ì—…ë°ì´íŠ¸
            existing_task = task_log_crud.get_by_task_id(session, task_id=task_id)
            if not existing_task:
                # ìƒˆ TaskLog ìƒì„±
                task_log_crud.create_task_log(
                    session,
                    task_id=task_id,
                    task_name=task.name if task else "unknown",
                    status="STARTED",
                    args=safe_json_dumps(args) if args else None,
                    kwargs=safe_json_dumps(kwargs) if kwargs else None
                )
                logger.info(f"ìƒˆ TaskLog ìƒì„±: {task_id}")
            else:
                # ê¸°ì¡´ TaskLog ìƒíƒœ ì—…ë°ì´íŠ¸
                task_log_crud.update_status(
                    session,
                    task_log=existing_task,
                    status="STARTED"
                )
                logger.info(f"TaskLog ìƒíƒœ ì—…ë°ì´íŠ¸: {task_id} -> STARTED")

            # TaskMetadata ìƒì„±
            task_metadata_crud.create_task_metadata(
                session,
                task_id=task_id,
                worker_name=get_worker_name() if hasattr(task, 'request') else None,
                queue_name=getattr(task.request, 'delivery_info', {}).get('routing_key', 'default') if hasattr(task,
                                                                                                               'request') else 'default',
                priority=getattr(task.request, 'priority', 0) if hasattr(task, 'request') else 0
            )
            logger.info(f"TaskMetadata ìƒì„±: {task_id}")

            # TaskExecutionHistoryì— ì‹œë„ ê¸°ë¡
            attempt_number = task_execution_history_crud.get_retry_count(session, task_id=task_id) + 1
            task_execution_history_crud.create_attempt(
                session,
                task_id=task_id,
                attempt_number=attempt_number,
                status="STARTED"
            )
            logger.info(f"TaskExecutionHistory ìƒì„±: {task_id}, attempt: {attempt_number}")

        except Exception as e:
            logger.error(f"task_prerun_handler ì˜¤ë¥˜: {e}",exc_info=True )


@task_success.connect
def task_success_handler(sender=None, result=None, **kwargs):
    """ì‘ì—… ì„±ê³µ ì²˜ë¦¬"""
    task_id = sender.request.id if sender and hasattr(sender, 'request') else None
    logger.info(f"âœ… SIGNAL: task_success ìˆ˜ì‹  - task_id: {task_id}")

    with get_db_manager().get_sync_session() as session:
        if not session:
            logger.error("âŒ DB ì„¸ì…˜ ìƒì„± ì‹¤íŒ¨ - task_success")
            return

        try:
            if not task_id:
                logger.warning("task_idë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                return

            # TaskLog ìƒíƒœ ì—…ë°ì´íŠ¸
            task_log = task_log_crud.get_by_task_id(session, task_id=task_id)
            if task_log:
                task_log_crud.update_status(
                    session,
                    task_log=task_log,
                    status="SUCCESS",
                    result=safe_json_dumps(result) if result else None
                )
                logger.info(f"TaskLog ì„±ê³µ ì²˜ë¦¬: {task_id}")

                # TaskExecutionHistory ì™„ë£Œ ì²˜ë¦¬
                latest_attempt = task_execution_history_crud.get_latest_attempt(session, task_id=task_id)
                if latest_attempt:
                    task_execution_history_crud.complete_attempt(
                        session,
                        execution_history=latest_attempt,
                        status="SUCCESS"
                    )

                # ChainExecution ì—…ë°ì´íŠ¸ (pipeline taskì¸ ê²½ìš°)
                if task_log.task_name and 'stage' in task_log.task_name:
                    # resultì—ì„œ chain_id ì¶”ì¶œ
                    chain_id = None
                    if isinstance(result, dict) and 'chain_id' in result:
                        chain_id = result['chain_id']

                    if chain_id:
                        chain_exec = chain_execution_crud.get_by_chain_id(session, chain_id=chain_id)
                        if chain_exec:
                            chain_execution_crud.increment_completed_tasks(session, chain_execution=chain_exec)
                            logger.info(f"ChainExecution ì§„í–‰ë¥  ì—…ë°ì´íŠ¸: {chain_id}")

            logger.info(f"ì‘ì—… ì„±ê³µ ì²˜ë¦¬ ì™„ë£Œ: {task_id}")

        except Exception as e:
            logger.error(f"task_success_handler ì˜¤ë¥˜: {e}",exc_info=True )
            # session.rollback() # context managerê°€ ì²˜ë¦¬


@task_failure.connect
def task_failure_handler(sender=None, task_id=None, exception=None, traceback=None, einfo=None, **kwargs):
    """ì‘ì—… ì‹¤íŒ¨ ì²˜ë¦¬"""
    logger.info(f"âŒ SIGNAL: task_failure ìˆ˜ì‹  - task_id: {task_id}")
    with get_db_manager().get_sync_session() as session:
        if not session:
            logger.error("âŒ DB ì„¸ì…˜ ìƒì„± ì‹¤íŒ¨ - task_failure")
            return

        try:
            if not task_id:
                logger.warning("task_idë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                return

            error_message = str(exception) if exception else "Unknown error"
            traceback_str = str(traceback) if traceback else None

            # TaskLog ìƒíƒœ ì—…ë°ì´íŠ¸
            task_log = task_log_crud.get_by_task_id(session, task_id=task_id)
            if task_log:
                task_log_crud.update_status(
                    session,
                    task_log=task_log,
                    status="FAILURE",
                    error=error_message
                )
                logger.info(f"TaskLog ì‹¤íŒ¨ ì²˜ë¦¬: {task_id}")

                # TaskExecutionHistory ì™„ë£Œ ì²˜ë¦¬
                latest_attempt = task_execution_history_crud.get_latest_attempt(session, task_id=task_id)
                if latest_attempt:
                    task_execution_history_crud.complete_attempt(
                        session,
                        execution_history=latest_attempt,
                        status="FAILURE",
                        error_message=error_message,
                        traceback=traceback_str
                    )

                # ChainExecution ì—…ë°ì´íŠ¸ (pipeline taskì¸ ê²½ìš°)
                if task_log.task_name and 'stage' in task_log.task_name:
                    # task args/kwargsì—ì„œ chain_id ì¶”ì¶œ ì‹œë„
                    chain_id = None
                    if task_log.kwargs:
                        try:
                            kwargs_dict = json.loads(task_log.kwargs)
                            chain_id = kwargs_dict.get('chain_id')
                        except:
                            pass

                    if not chain_id and task_log.args:
                        try:
                            args_list = json.loads(task_log.args)
                            if args_list:
                                chain_id = get_chain_id_from_args(args_list)
                        except:
                            pass

                    if chain_id:
                        chain_exec = chain_execution_crud.get_by_chain_id(session, chain_id=chain_id)
                        if chain_exec:
                            chain_execution_crud.increment_failed_tasks(session, chain_execution=chain_exec)
                            logger.info(f"ChainExecution ì‹¤íŒ¨ ì¹´ìš´íŠ¸ ì¦ê°€: {chain_id}")

            logger.info(f"ì‘ì—… ì‹¤íŒ¨ ì²˜ë¦¬ ì™„ë£Œ: {task_id}")

        except Exception as e:
            logger.error(f"task_failure_handler ì˜¤ë¥˜: {e}",exc_info=True )
            # session.rollback() # context managerê°€ ì²˜ë¦¬


@task_retry.connect
def task_retry_handler(sender=None, task_id=None, reason=None, einfo=None, **kwargs):
    """ì‘ì—… ì¬ì‹œë„ ì²˜ë¦¬"""
    logger.info(f"ğŸ”„ SIGNAL: task_retry ìˆ˜ì‹  - task_id: {task_id}")
    with get_db_manager().get_sync_session() as session:
        if not session:
            logger.error("âŒ DB ì„¸ì…˜ ìƒì„± ì‹¤íŒ¨ - task_retry")
            return

        try:
            if not task_id:
                logger.warning("task_idë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                return

            error_message = str(reason) if reason else "Retry triggered"

            # TaskLog ì¬ì‹œë„ ì¹´ìš´íŠ¸ ì¦ê°€
            task_log = task_log_crud.get_by_task_id(session, task_id=task_id)
            if task_log:
                task_log_crud.increment_retries(session, task_log=task_log)
                task_log_crud.update_status(
                    session,
                    task_log=task_log,
                    status="RETRY",
                    error=error_message
                )
                logger.info(f"TaskLog ì¬ì‹œë„ ì²˜ë¦¬: {task_id}")

            # ìƒˆë¡œìš´ TaskExecutionHistory ì‹œë„ ê¸°ë¡
            attempt_number = task_execution_history_crud.get_retry_count(session, task_id=task_id) + 1
            task_execution_history_crud.create_attempt(
                session,
                task_id=task_id,
                attempt_number=attempt_number,
                status="RETRY"
            )
            logger.info(f"TaskExecutionHistory ì¬ì‹œë„ ê¸°ë¡: {task_id}, attempt: {attempt_number}")

        except Exception as e:
            logger.error(f"task_retry_handler ì˜¤ë¥˜: {e}",exc_info=True )
            # session.rollback() # context managerê°€ ì²˜ë¦¬


@task_revoked.connect
def task_revoked_handler(sender=None, request=None, reason=None, **kwargs):
    """ì‘ì—… ì·¨ì†Œ ì²˜ë¦¬"""
    task_id = request.id if request else None
    logger.info(f"ğŸš« SIGNAL: task_revoked ìˆ˜ì‹  - task_id: {task_id}")

    with get_db_manager().get_sync_session() as session:
        if not session:
            logger.error("âŒ DB ì„¸ì…˜ ìƒì„± ì‹¤íŒ¨ - task_revoked")
            return

        try:
            if not task_id:
                logger.warning("task_idë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                return

            # TaskLog ìƒíƒœ ì—…ë°ì´íŠ¸
            task_log = task_log_crud.get_by_task_id(session, task_id=task_id)
            if task_log:
                task_log_crud.update_status(
                    session,
                    task_log=task_log,
                    status="REVOKED",
                    error=str(reason) if reason else "Task revoked"
                )
                logger.info(f"TaskLog ì·¨ì†Œ ì²˜ë¦¬: {task_id}")

                # TaskExecutionHistory ì™„ë£Œ ì²˜ë¦¬
                latest_attempt = task_execution_history_crud.get_latest_attempt(session, task_id=task_id)
                if latest_attempt:
                    task_execution_history_crud.complete_attempt(
                        session,
                        execution_history=latest_attempt,
                        status="REVOKED",
                        error_message=str(reason) if reason else "Task revoked"
                    )

        except Exception as e:
            logger.error(f"task_revoked_handler ì˜¤ë¥˜: {e}" ,exc_info=True )
            


# ì›Œì»¤ ê´€ë ¨ ì‹ í˜¸ ì²˜ë¦¬

@worker_ready.connect
def worker_ready_handler(sender=None, **kwargs):
    """ì›Œì»¤ ì¤€ë¹„ ì™„ë£Œ ì²˜ë¦¬"""
    worker_name = get_worker_name(sender)
    logger.info(f"ğŸŸ¢ SIGNAL: worker_ready ìˆ˜ì‹  - worker: {worker_name}")


@worker_shutdown.connect
def worker_shutdown_handler(sender=None, **kwargs):
    """ì›Œì»¤ ì¢…ë£Œ ì²˜ë¦¬"""
    worker_name = get_worker_name(sender)
    logger.info(f"ğŸ”´ SIGNAL: worker_shutdown ìˆ˜ì‹  - worker: {worker_name}")


@heartbeat_sent.connect
def heartbeat_handler(sender=None, **kwargs):
    """í•˜íŠ¸ë¹„íŠ¸ ì²˜ë¦¬"""
    # í•˜íŠ¸ë¹„íŠ¸ëŠ” ë„ˆë¬´ ìì£¼ ë°œìƒí•˜ë¯€ë¡œ ë¡œê¹…í•˜ì§€ ì•ŠìŒ
    pass


# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ë° ìŠ¤ì¼€ì¤„ ì‘ì—…

def collect_queue_stats():
    """í í†µê³„ ìˆ˜ì§‘ ì‘ì—…"""
    from celery import current_app
    with get_db_manager().get_sync_session() as session:
        if not session:
            return

        session: Session

        inspect = current_app.control.inspect()

        # í™œì„± ì‘ì—… ì¡°íšŒ
        active_tasks = inspect.active()
        reserved_tasks = inspect.reserved()
        scheduled_tasks = inspect.scheduled()

        for worker_name, tasks in (active_tasks or {}).items():
            # QueueStats ì—…ë°ì´íŠ¸
            queue_stat = session.query(QueueStats).filter_by(
                queue_name='celery',
                worker_name=worker_name
            ).first()

            if not queue_stat:
                queue_stat = QueueStats(
                    queue_name='celery',
                    worker_name=worker_name,
                    active_tasks=len(tasks),
                    reserved_tasks=len(reserved_tasks.get(worker_name, [])),
                    scheduled_tasks=len(scheduled_tasks.get(worker_name, []))
                )
                session.add(queue_stat)
            else:
                queue_stat.active_tasks = len(tasks)
                queue_stat.reserved_tasks = len(reserved_tasks.get(worker_name, []))
                queue_stat.scheduled_tasks = len(scheduled_tasks.get(worker_name, []))
                queue_stat.last_updated = datetime.now()


def get_task_statistics(session):
    """ì‘ì—… í†µê³„ ì¡°íšŒ"""
    try:
        stats = session.query(
            TaskLog.status, session.query(TaskLog).filter_by(status=TaskLog.status).count()) \
            .group_by(TaskLog.status).all()

        return {status: count for status, count in stats}
    except Exception as e:
        logger.error(f"ì‘ì—… í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return {}


def cleanup_old_records(session, days=30):
    try:
        cutoff_date = datetime.now() - timedelta(days=days)

        # ì™„ë£Œëœ ì‘ì—…ì˜ ì˜¤ë˜ëœ ë ˆì½”ë“œ ì‚­ì œ
        deleted_count = session.query(TaskLog) \
            .filter(TaskLog.completed_at < cutoff_date) \
            .filter(TaskLog.status.in_(['SUCCESS', 'FAILURE', 'REVOKED'])) \
            .delete()

        session.commit()
        logger.info(f"ì˜¤ë˜ëœ ì‘ì—… ë ˆì½”ë“œ {deleted_count}ê°œ ì •ë¦¬ë¨")

        return deleted_count
    except Exception as e:
        logger.error(f"ë ˆì½”ë“œ ì •ë¦¬ ì‹¤íŒ¨: {e}")
        session.rollback()
        return 0