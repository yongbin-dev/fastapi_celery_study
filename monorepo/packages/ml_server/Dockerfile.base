# Dockerfile.ml-gpu-base - ML GPU 베이스 이미지
# CUDA + cuDNN + torch GPU + 기본 ML 라이브러리

# 1. NVIDIA CUDA + cuDNN 베이스 (runtime → devel로 변경)
# devel 이미지는 개발 도구와 완전한 CUDA 라이브러리를 포함
FROM nvidia/cuda:11.8.0-cudnn8-devel-ubuntu20.04

WORKDIR /app

# 2. 시스템 의존성 설치
# devel 이미지는 이미 모든 CUDA 라이브러리를 포함하므로 심볼릭 링크 불필요
RUN apt-get update && apt-get install -y --no-install-recommends \
    build-essential curl git \
    libglib2.0-0 libsm6 libxext6 libxrender1 libgomp1 libgl1 \
    python3-dev python3-pip \
    && rm -rf /var/lib/apt/lists/*

# 3. pip 업그레이드
RUN pip install --upgrade pip

# 4. UV 설치
COPY --from=ghcr.io/astral-sh/uv:latest /uv /usr/local/bin/uv

# 5. 의존성 파일 복사 (경로 수정)
COPY packages/ml_server/pyproject.toml ./
COPY packages/shared /app/shared
COPY uv.lock ./

# 6. 공통 의존성 + ML 베이스 설치 (캐시 활용)
RUN --mount=type=cache,target=/root/.cache/uv \
    uv sync --python 3.12 --extra ml-base --no-dev && \
    uv pip install -e /app/shared

# 7. 환경 변수
ENV PYTHONPATH=/app \
    TZ=Asia/Seoul \
    FLAGS_fraction_of_gpu_memory_to_use=0.9 \
    FLAGS_use_gpu=True \
    LD_LIBRARY_PATH=/usr/local/cuda/lib64:/usr/local/cuda-11.8/targets/x86_64-linux/lib:/usr/lib/x86_64-linux-gnu:$LD_LIBRARY_PATH \
    CUDA_HOME=/usr/local/cuda-11.8 \
    HOST=0.0.0.0 \
    PORT=8001

# 8. 포트 노출
EXPOSE 8001