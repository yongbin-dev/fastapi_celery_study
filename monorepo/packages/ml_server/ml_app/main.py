"""
ML Server Main Application
AI/ML ëª¨ë¸ ì¶”ë¡ ì„ ë‹´ë‹¹í•˜ëŠ” ì„œë²„
"""

import asyncio
from contextlib import asynccontextmanager

from fastapi import FastAPI
from shared.config import settings
from shared.core.logging import get_logger

logger = get_logger(__name__)

# gRPC í™œì„±í™” ì—¬ë¶€
USE_GRPC = settings.USE_GRPC == "true"


@asynccontextmanager
async def lifespan(app: FastAPI):
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒëª…ì£¼ê¸° ê´€ë¦¬"""

    # ì‹œì‘ ì‹œ

    # ì‹œì‘ ì‹œ
    logger.info("ğŸš€ ML ì„œë²„ ì‹œì‘")

    grpc_task = None
    if USE_GRPC:
        # gRPC ì„œë²„ë¥¼ ë³„ë„ íƒœìŠ¤í¬ë¡œ ì‹œì‘
        from ml_app.grpc_services.server import serve

        grpc_task = asyncio.create_task(serve())
        logger.info("âœ… gRPC ì„œë²„ íƒœìŠ¤í¬ ì‹œì‘")
    else:
        logger.info("âš ï¸  gRPC ë¹„í™œì„±í™” (USE_GRPC=false)")

    yield

    # ì¢…ë£Œ ì‹œ
    logger.info("ğŸ›‘ ML ì„œë²„ ì¢…ë£Œ")
    if grpc_task:
        grpc_task.cancel()
        try:
            await grpc_task
        except asyncio.CancelledError:
            logger.info("gRPC ì„œë²„ íƒœìŠ¤í¬ ì¢…ë£Œ")


app = FastAPI(
    title="ML Model Server",
    version="1.0.0",
    description="AI/ML ëª¨ë¸ ì¶”ë¡  ì„œë²„ - OCR, LLM ë“±",
    lifespan=lifespan,
)
