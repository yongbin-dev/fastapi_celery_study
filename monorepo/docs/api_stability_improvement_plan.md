# `/extract/pdf` 엔드포인트 안정성 개선 방안

## 1. 현황 및 문제점

현재 `/extract/pdf` API 엔드포인트는 동기 방식으로 동작하며, 다음과 같은 심각한 안정성 문제점을 내포하고 있습니다.

- **과도한 메모리 사용**:
  - PDF 파일을 서버 메모리에 한 번에 로드하고, 각 페이지를 이미지로 변환하는 과정에서 추가 메모리를 사용합니다.
  - 대용량 파일 또는 다수의 동시 요청 발생 시, 메모리 부족(Out of Memory)으로 인해 서버가 다운될 수 있습니다.

- **동기 블로킹(Blocking) 호출**:
  - ML 서버의 OCR API를 `await`를 사용해 동기적으로 호출하고 응답을 기다립니다.
  - ML 서버의 처리 시간이 길어질수록 API 서버의 워커(Worker) 프로세스가 점유되어 다른 요청을 처리할 수 없게 됩니다.
  - 이는 API 서버 전체의 처리량(Throughput) 저하와 응답 시간 증가로 이어집니다.

- **강한 결합(Tightly Coupled) 구조**:
  - API 서버가 ML 서버에 직접적으로 의존하고 있어, ML 서버의 장애가 즉시 API 서버의 장애로 전파됩니다. (연쇄 장애)

> **결론:** 현재 구조는 운영 환경에서 여러 배치 요청을 안정적으로 처리하기에 매우 부적합하며, 장애 발생 가능성이 매우 높습니다.

---

## 2. 개선 목표

- **안정성 및 가용성 확보**: 대용량 트래픽 및 예외 상황에서도 서비스가 중단되지 않도록 보장합니다.
- **성능 및 확장성 향상**: 시스템 리소스를 효율적으로 사용하고, 향후 요청 증가에 유연하게 대응할 수 있는 구조를 마련합니다.
- **장애 격리**: 특정 컴포넌트의 장애가 전체 시스템으로 확산되는 것을 방지합니다.

---

## 3. 상세 개선 방안

핵심 개선 방향은 **비동기 태스크 기반 아키텍처**로 전환하는 것입니다. 프로젝트에 이미 `Celery`와 `Redis`가 도입되어 있으므로 이를 적극 활용합니다.

### 3.1. 아키텍처 변경: 동기 → 비동기 처리

![개선 아키텍처](https-placeholder-for-diagram)
*(추후 아키텍처 다이어그램 이미지 삽입)*

1.  **클라이언트**는 API 서버에 PDF 처리 요청을 보냅니다.
2.  **API 서버 (`/extract/pdf`)**:
    - 요청을 받으면 파일을 즉시 클라우드 스토리지(예: Supabase Storage)에 업로드합니다.
    - PDF 처리에 필요한 메타데이터(파일 경로, 사용자 정보 등)를 포함한 작업을 **Celery 태스크**로 생성하여 **Redis(메시지 브로커)**에 전달합니다.
    - 작업이 성공적으로 전달되면, 클라이언트에게 즉시 **`202 Accepted`** 상태 코드와 함께 **작업 ID(`task_id`)**를 반환합니다.
3.  **Celery 워커 (ML 서버 또는 별도 워커)**:
    - Redis를 구독하며 처리할 작업을 가져옵니다.
    - 스토리지에서 PDF 파일을 다운로드하여 스트리밍 방식으로 처리하거나, 페이지 단위로 나누어 메모리 사용량을 최소화합니다.
    - ML 서버 API를 호출하여 OCR을 수행합니다.
    - 처리 결과를 데이터베이스에 저장하고, 작업의 최종 상태(성공/실패)를 업데이트합니다.
4.  **클라이언트**:
    - 발급받은 `task_id`를 사용하여 **상태 조회 API (`/extract/status/{task_id}`)**를 주기적으로 호출(Polling)하여 작업 진행 상황을 확인하고, 완료 시 결과를 가져옵니다.

### 3.2. API 변경 사항

#### 가. `POST /extract/pdf` (기존 엔드포인트 수정)

- **역할**: PDF 파일 업로드 및 비동기 작업 생성 요청.
- **수정 내용**:
  - 내부 로직에서 PDF 파일을 직접 처리하고 ML 서버를 호출하는 부분을 제거합니다.
  - `pdf_file.read()`를 사용하여 메모리에 올리는 대신, 파일을 스트리밍 방식으로 스토리지에 업로드합니다.
  - Celery `send_task` 또는 `@task` 데코레이터를 사용하여 비동기 작업을 메시지 큐에 등록합니다.
- **응답**:
  - 성공 시: `202 Accepted`
    ```json
    {
      "task_id": "some-unique-task-id",
      "status": "pending",
      "message": "PDF 처리 작업이 성공적으로 접수되었습니다."
    }
    ```
  - 실패 시: `4xx` 또는 `5xx` 에러 (파일 업로드 실패, 작업 등록 실패 등)

#### 나. `GET /extract/status/{task_id}` (신규 엔드포인트 추가)

- **역할**: 비동기 처리 작업의 현재 상태 및 결과 조회.
- **응답**:
  - **작업 진행 중**:
    ```json
    {
      "task_id": "some-unique-task-id",
      "status": "processing",
      "progress": 35 // (선택적) 진행률
    }
    ```
  - **작업 완료**:
    ```json
    {
      "task_id": "some-unique-task-id",
      "status": "completed",
      "result": {
        // OCR 결과 데이터
      }
    }
    ```
  - **작업 실패**:
    ```json
    {
      "task_id": "some-unique-task-id",
      "status": "failed",
      "error_message": "오류 원인에 대한 설명"
    }
    ```

### 3.3. Celery 비동기 작업 구현

- **태스크 정의 (`tasks.py`)**:
  - PDF 파일을 스토리지에서 다운로드합니다.
  - `fitz` 라이브러리 사용 시, 파일을 스트림으로 열거나 페이지 단위로 처리하여 메모리 사용을 최적화합니다.
  - ML 서버 호출 로직을 이관합니다.
  - **재시도 및 오류 처리**: ML 서버 일시적 오류 등 예외 발생 시, Celery의 재시도(retry) 메커니즘을 적용하여 안정성을 높입니다.
  - **상태 업데이트**: 작업의 단계별 진행 상황(시작, 처리 중, 완료, 실패)을 DB나 Redis에 기록하여 상태 조회 API가 참조할 수 있도록 합니다.

---

## 4. 기대 효과

- **API 응답 시간 단축**: 무거운 작업을 백그라운드로 넘기고 즉시 응답하므로 사용자 경험이 향상됩니다.
- **서버 부하 분산 및 안정성 증대**: 동시 요청이 많아져도 작업을 큐에 쌓아두고 워커가 순차적으로 처리하므로, API 서버의 부하가 급증하지 않고 안정적인 서비스가 가능합니다.
- **메모리 사용량 최적화**: 대용량 파일을 스트리밍 방식으로 처리하여 메모리 문제를 근본적으로 해결합니다.
- **장애 내성 및 복원력 강화**: 메시지 큐를 통해 API 서버와 ML 처리 워커가 분리되어, 한쪽의 장애가 다른 쪽에 미치는 영향을 최소화하고 작업 재시도 등을 통해 복원력을 높일 수 있습니다.
- **확장성 확보**: 작업량이 많아질 경우 Celery 워커의 수만 늘려 간단하게 시스템 전체의 처리량을 늘릴 수 있습니다.
