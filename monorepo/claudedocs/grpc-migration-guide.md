# gRPC ë§ˆì´ê·¸ë ˆì´ì…˜ ê°€ì´ë“œ
## ML Server â†” Celery Worker í†µì‹  ê°œì„ 

---

## ğŸ“‹ ëª©ì°¨
1. [í˜„ì¬ ì•„í‚¤í…ì²˜ ë¶„ì„](#í˜„ì¬-ì•„í‚¤í…ì²˜-ë¶„ì„)
2. [gRPC ë„ì… ë°°ê²½ ë° ì¥ì ](#grpc-ë„ì…-ë°°ê²½-ë°-ì¥ì )
3. [ë§ˆì´ê·¸ë ˆì´ì…˜ ì „ëµ](#ë§ˆì´ê·¸ë ˆì´ì…˜-ì „ëµ)
4. [êµ¬í˜„ ë‹¨ê³„](#êµ¬í˜„-ë‹¨ê³„)
5. [Proto íŒŒì¼ ì •ì˜](#proto-íŒŒì¼-ì •ì˜)
6. [ML Server êµ¬í˜„](#ml-server-êµ¬í˜„)
7. [Celery Worker êµ¬í˜„](#celery-worker-êµ¬í˜„)
8. [ë°°í¬ ë° ì „í™˜ ì „ëµ](#ë°°í¬-ë°-ì „í™˜-ì „ëµ)
9. [ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬](#ì„±ëŠ¥-ë²¤ì¹˜ë§ˆí¬)
10. [ë¬¸ì œ í•´ê²° ê°€ì´ë“œ](#ë¬¸ì œ-í•´ê²°-ê°€ì´ë“œ)

---

## í˜„ì¬ ì•„í‚¤í…ì²˜ ë¶„ì„

### ğŸ” í˜„ì¬ í†µì‹  ë°©ì‹ (HTTP/REST)

```python
# celery_worker/tasks/stages/ocr_stage.py:58
async with httpx.AsyncClient(timeout=300.0) as client:
    response = await client.post(
        f"{self.ml_server_url}/ocr/extract",
        json={
            "public_image_path": context.public_file_path,
            "private_image_path": context.input_file_path,
        }
    )
```

### ğŸ“Š í˜„ì¬ í†µì‹  íë¦„

```
[Celery Worker - OCRStage]
    â†“ HTTP POST /ocr/extract
    â†“ JSON payload (image paths)
    â†“ httpx.AsyncClient (timeout 300s)

[ML Server - FastAPI]
    â†“ FastAPI Router
    â†“ OCRModel.predict()
    â†“ OCR Engine (EasyOCR/PaddleOCR)
    â†“ JSON response

[Celery Worker]
    â†“ Parse JSON
    â†“ Create OCRResult
    â†“ Save to Redis
```

### âš ï¸ í˜„ì¬ ë¬¸ì œì 

1. **JSON ì§ë ¬í™” ì˜¤ë²„í—¤ë“œ**
   - ì´ë¯¸ì§€ ê²½ë¡œ, ë©”íƒ€ë°ì´í„°ë¥¼ JSONìœ¼ë¡œ ë³€í™˜
   - ëŒ€ëŸ‰ ì²˜ë¦¬ ì‹œ ì§ë ¬í™” ë¹„ìš© ì¦ê°€

2. **HTTP í”„ë¡œí† ì½œ ì˜¤ë²„í—¤ë“œ**
   - HTTP/1.1 í—¤ë” ì˜¤ë²„í—¤ë“œ
   - ì»¤ë„¥ì…˜ ìˆ˜ë¦½ ë¹„ìš©
   - Keep-alive ê´€ë¦¬ ë³µì¡ì„±

3. **íƒ€ì… ì•ˆì •ì„± ë¶€ì¡±**
   - ëŸ°íƒ€ì„ì—ë§Œ ìŠ¤í‚¤ë§ˆ ê²€ì¦
   - Pydanticìœ¼ë¡œ ê²€ì¦í•˜ì§€ë§Œ í†µì‹  ë ˆë²¨ì—ì„œ ë³´ì¥ ì•ˆ ë¨

4. **ìŠ¤íŠ¸ë¦¬ë° ì§€ì› ë¶€ì¡±**
   - ëŒ€ìš©ëŸ‰ ì´ë¯¸ì§€ ë°°ì¹˜ ì²˜ë¦¬ ì‹œ ì œí•œì 
   - ì§„í–‰ ìƒí™© ìŠ¤íŠ¸ë¦¬ë° ë¶ˆê°€

---

## gRPC ë„ì… ë°°ê²½ ë° ì¥ì 

### âœ… gRPC ì¥ì 

#### 1. **ì„±ëŠ¥ í–¥ìƒ**
- **HTTP/2 ê¸°ë°˜**: ë©€í‹°í”Œë ‰ì‹±, í—¤ë” ì••ì¶•
- **Protobuf ì§ë ¬í™”**: JSON ëŒ€ë¹„ 3-10ë°° ë¹ ë¦„, í¬ê¸° 20-30% ê°ì†Œ
- **ë°”ì´ë„ˆë¦¬ í”„ë¡œí† ì½œ**: íŒŒì‹± ì˜¤ë²„í—¤ë“œ ìµœì†Œí™”

```
JSON vs Protobuf (ì˜ˆìƒ)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Metric      â”‚   JSON   â”‚ Protobuf â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ì§ë ¬í™” ì‹œê°„      â”‚  100ms   â”‚   30ms   â”‚
â”‚ ë©”ì‹œì§€ í¬ê¸°      â”‚  1.5KB   â”‚   1KB    â”‚
â”‚ íŒŒì‹± ì‹œê°„        â”‚   80ms   â”‚   20ms   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 2. **íƒ€ì… ì•ˆì „ì„±**
- Proto íŒŒì¼ë¡œ ê³„ì•½ ëª…ì‹œ
- ì»´íŒŒì¼ íƒ€ì„ íƒ€ì… ê²€ì¦
- IDE ìë™ì™„ì„± ì§€ì›

#### 3. **ìŠ¤íŠ¸ë¦¬ë° ì§€ì›**
- Server Streaming: ML ì„œë²„ â†’ ì›Œì»¤ (ì§„í–‰ ìƒí™©)
- Client Streaming: ì›Œì»¤ â†’ ML ì„œë²„ (ë°°ì¹˜ ì´ë¯¸ì§€)
- Bidirectional: ì–‘ë°©í–¥ ì‹¤ì‹œê°„ í†µì‹ 

#### 4. **ì–¸ì–´ ì¤‘ë¦½ì„±**
- Proto íŒŒì¼ë¡œ Python, Go, Java ë“± ìë™ ìƒì„±
- í–¥í›„ ë‹¤ë¥¸ ì–¸ì–´ë¡œ í™•ì¥ ìš©ì´

---

## ë§ˆì´ê·¸ë ˆì´ì…˜ ì „ëµ

### ğŸ¯ ë‹¨ê³„ë³„ ë§ˆì´ê·¸ë ˆì´ì…˜ (Strangler Fig Pattern)

```
Phase 1: gRPC ì¸í”„ë¼ êµ¬ì¶• (1ì£¼)
    â†“
Phase 2: Dual Mode ìš´ì˜ (2ì£¼)
    â”œâ”€ HTTP (ê¸°ì¡´)
    â””â”€ gRPC (ì‹ ê·œ) - Feature Flag
    â†“
Phase 3: gRPC ê¸°ë³¸ ëª¨ë“œ (1ì£¼)
    â”œâ”€ gRPC (ê¸°ë³¸)
    â””â”€ HTTP (í´ë°±)
    â†“
Phase 4: HTTP ì œê±° (1ì£¼)
    â””â”€ gRPC only
```

### ğŸ”§ í•˜ìœ„ í˜¸í™˜ì„± ìœ ì§€ ì „ëµ

```python
# í™˜ê²½ ë³€ìˆ˜ë¡œ í†µì‹  ë°©ì‹ ì„ íƒ
USE_GRPC = os.getenv("USE_GRPC", "false").lower() == "true"

if USE_GRPC:
    result = await grpc_client.extract_ocr(request)
else:
    result = await http_client.post("/ocr/extract", json=request)
```

---

## êµ¬í˜„ ë‹¨ê³„

### Step 1: í”„ë¡œì íŠ¸ êµ¬ì¡° ì¤€ë¹„

```bash
monorepo/
â”œâ”€â”€ packages/
â”‚   â”œâ”€â”€ shared/
â”‚   â”‚   â””â”€â”€ shared/
â”‚   â”‚       â””â”€â”€ grpc/
â”‚   â”‚           â”œâ”€â”€ protos/           # Proto íŒŒì¼
â”‚   â”‚           â”‚   â”œâ”€â”€ ocr.proto
â”‚   â”‚           â”‚   â”œâ”€â”€ llm.proto
â”‚   â”‚           â”‚   â””â”€â”€ common.proto
â”‚   â”‚           â”œâ”€â”€ generated/        # ìƒì„±ëœ Python ì½”ë“œ
â”‚   â”‚           â”‚   â”œâ”€â”€ ocr_pb2.py
â”‚   â”‚           â”‚   â”œâ”€â”€ ocr_pb2_grpc.py
â”‚   â”‚           â”‚   â””â”€â”€ __init__.py
â”‚   â”‚           â””â”€â”€ utils/           # gRPC í—¬í¼
â”‚   â”‚               â”œâ”€â”€ server.py
â”‚   â”‚               â””â”€â”€ client.py
â”‚   â”‚
â”‚   â”œâ”€â”€ ml_server/
â”‚   â”‚   â””â”€â”€ ml_app/
â”‚   â”‚       â””â”€â”€ grpc_services/      # gRPC ì„œë¹„ìŠ¤ êµ¬í˜„
â”‚   â”‚           â”œâ”€â”€ __init__.py
â”‚   â”‚           â”œâ”€â”€ ocr_service.py
â”‚   â”‚           â””â”€â”€ server.py
â”‚   â”‚
â”‚   â””â”€â”€ celery_worker/
â”‚       â””â”€â”€ tasks/
â”‚           â””â”€â”€ grpc_clients/       # gRPC í´ë¼ì´ì–¸íŠ¸
â”‚               â”œâ”€â”€ __init__.py
â”‚               â””â”€â”€ ocr_client.py
```

### Step 2: ì˜ì¡´ì„± ì¶”ê°€

```toml
# packages/shared/pyproject.toml
[project]
dependencies = [
    # ... ê¸°ì¡´ ì˜ì¡´ì„±
    "grpcio>=1.60.0",
    "grpcio-tools>=1.60.0",
    "protobuf>=4.25.0",
]

# packages/ml_server/pyproject.toml
[project]
dependencies = [
    # ... ê¸°ì¡´ ì˜ì¡´ì„±
    "grpcio-reflection>=1.60.0",  # ì„œë²„ ë¦¬í”Œë ‰ì…˜
]
```

---

## Proto íŒŒì¼ ì •ì˜

### ğŸ“ common.proto (ê³µí†µ íƒ€ì…)

```protobuf
// packages/shared/shared/grpc/protos/common.proto
syntax = "proto3";

package common;

// íƒ€ì„ìŠ¤íƒ¬í”„
message Timestamp {
    int64 seconds = 1;
    int32 nanos = 2;
}

// ë°”ìš´ë”© ë°•ìŠ¤
message BoundingBox {
    repeated float coordinates = 1;  // [x1, y1, x2, y2, x3, y3, x4, y4]
}

// ë©”íƒ€ë°ì´í„°
message Metadata {
    map<string, string> data = 1;
}

// ì—ëŸ¬ ì •ë³´
message ErrorInfo {
    string code = 1;
    string message = 2;
    string details = 3;
}

// ìƒíƒœ ì½”ë“œ
enum Status {
    STATUS_UNKNOWN = 0;
    STATUS_SUCCESS = 1;
    STATUS_FAILURE = 2;
    STATUS_PENDING = 3;
    STATUS_IN_PROGRESS = 4;
}
```

### ğŸ“ ocr.proto (OCR ì„œë¹„ìŠ¤)

```protobuf
// packages/shared/shared/grpc/protos/ocr.proto
syntax = "proto3";

package ocr;

import "common.proto";

// ============================================
// OCR ì¶”ì¶œ ì„œë¹„ìŠ¤
// ============================================

service OCRService {
    // ë‹¨ì¼ ì´ë¯¸ì§€ OCR ì¶”ì¶œ
    rpc ExtractText(OCRRequest) returns (OCRResponse);

    // ë°°ì¹˜ ì´ë¯¸ì§€ OCR ì¶”ì¶œ (Server Streaming)
    rpc ExtractTextBatch(OCRBatchRequest) returns (stream OCRBatchProgress);

    // ìƒíƒœ í™•ì¸
    rpc CheckHealth(HealthCheckRequest) returns (HealthCheckResponse);
}

// ============================================
// ìš”ì²­/ì‘ë‹µ ë©”ì‹œì§€
// ============================================

// OCR ìš”ì²­
message OCRRequest {
    string public_image_path = 1;
    string private_image_path = 2;
    string language = 3;                    // ê¸°ë³¸ê°’: "korean"
    float confidence_threshold = 4;         // ê¸°ë³¸ê°’: 0.5
    bool use_angle_cls = 5;                 // ê¸°ë³¸ê°’: true
    common.Metadata options = 6;            // ì¶”ê°€ ì˜µì…˜
}

// OCR ì‘ë‹µ
message OCRResponse {
    common.Status status = 1;
    string text = 2;                        // ì¶”ì¶œëœ ì „ì²´ í…ìŠ¤íŠ¸
    float overall_confidence = 3;           // ì „ì²´ ì‹ ë¢°ë„
    repeated TextBox text_boxes = 4;        // í…ìŠ¤íŠ¸ ë°•ìŠ¤ ë¦¬ìŠ¤íŠ¸
    common.Metadata metadata = 5;           // ì—”ì§„ ì •ë³´, ì²˜ë¦¬ ì‹œê°„ ë“±
    common.ErrorInfo error = 6;             // ì—ëŸ¬ ì •ë³´ (ì‹¤íŒ¨ ì‹œ)
}

// í…ìŠ¤íŠ¸ ë°•ìŠ¤
message TextBox {
    string text = 1;
    float confidence = 2;
    common.BoundingBox bbox = 3;
}

// ============================================
// ë°°ì¹˜ ì²˜ë¦¬
// ============================================

// ë°°ì¹˜ ìš”ì²­
message OCRBatchRequest {
    repeated ImagePath image_paths = 1;
    string language = 2;
    float confidence_threshold = 3;
    bool use_angle_cls = 4;
}

// ì´ë¯¸ì§€ ê²½ë¡œ
message ImagePath {
    string public_path = 1;
    string private_path = 2;
}

// ë°°ì¹˜ ì§„í–‰ ìƒí™© (ìŠ¤íŠ¸ë¦¬ë°)
message OCRBatchProgress {
    string batch_id = 1;
    int32 total_images = 2;
    int32 processed_images = 3;
    OCRResponse current_result = 4;         // í˜„ì¬ ì²˜ë¦¬ ê²°ê³¼
    float progress_percentage = 5;
}

// ============================================
// í—¬ìŠ¤ ì²´í¬
// ============================================

message HealthCheckRequest {
    string service_name = 1;
}

message HealthCheckResponse {
    common.Status status = 1;
    string engine_type = 2;                 // "easyocr" | "paddleocr" | "mock"
    bool model_loaded = 3;
    string version = 4;
}
```

### ğŸ“ llm.proto (LLM ì„œë¹„ìŠ¤)

```protobuf
// packages/shared/shared/grpc/protos/llm.proto
syntax = "proto3";

package llm;

import "common.proto";

service LLMService {
    // í…ìŠ¤íŠ¸ ë¶„ì„
    rpc AnalyzeText(LLMRequest) returns (LLMResponse);

    // ìŠ¤íŠ¸ë¦¬ë° ë¶„ì„ (í† í°ë³„ ë°˜í™˜)
    rpc AnalyzeTextStream(LLMRequest) returns (stream LLMStreamResponse);
}

message LLMRequest {
    string text = 1;
    string prompt = 2;
    common.Metadata options = 3;
}

message LLMResponse {
    common.Status status = 1;
    string analysis = 2;
    float confidence = 3;
    map<string, string> entities = 4;
    common.Metadata metadata = 5;
    common.ErrorInfo error = 6;
}

message LLMStreamResponse {
    string token = 1;
    bool is_complete = 2;
}
```

---

## ML Server êµ¬í˜„

### ğŸ“¦ gRPC ì„œë¹„ìŠ¤ êµ¬í˜„

```python
# packages/ml_server/ml_app/grpc_services/ocr_service.py
"""OCR gRPC ì„œë¹„ìŠ¤ êµ¬í˜„"""

import grpc
from shared.grpc.generated import ocr_pb2, ocr_pb2_grpc, common_pb2
from shared.core.logging import get_logger
from ml_app.models.ocr_model import get_ocr_model
from shared.service.common_service import CommonService

logger = get_logger(__name__)


class OCRServiceServicer(ocr_pb2_grpc.OCRServiceServicer):
    """OCR gRPC ì„œë¹„ìŠ¤"""

    def __init__(self):
        self.common_service = CommonService()
        logger.info("OCR gRPC ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")

    async def ExtractText(
        self,
        request: ocr_pb2.OCRRequest,
        context: grpc.aio.ServicerContext
    ) -> ocr_pb2.OCRResponse:
        """ë‹¨ì¼ ì´ë¯¸ì§€ OCR ì¶”ì¶œ

        Args:
            request: OCR ìš”ì²­
            context: gRPC ì»¨í…ìŠ¤íŠ¸

        Returns:
            OCR ì‘ë‹µ
        """
        try:
            logger.info(f"OCR ìš”ì²­: {request.private_image_path}")

            # 1. ì´ë¯¸ì§€ ë¡œë“œ
            image_data = await self.common_service.load_image(
                request.private_image_path
            )

            # 2. OCR ëª¨ë¸ ì‹¤í–‰
            model = get_ocr_model(
                use_angle_cls=request.use_angle_cls,
                lang=request.language or "korean"
            )

            result = model.predict(
                image_data,
                confidence_threshold=request.confidence_threshold or 0.5
            )

            # 3. Protobuf ì‘ë‹µ ìƒì„±
            response = ocr_pb2.OCRResponse(
                status=common_pb2.STATUS_SUCCESS,
                text=result.text,
                overall_confidence=result.confidence
            )

            # 4. í…ìŠ¤íŠ¸ ë°•ìŠ¤ ë³€í™˜
            for box in result.text_boxes:
                text_box = ocr_pb2.TextBox(
                    text=box.text,
                    confidence=box.confidence,
                    bbox=common_pb2.BoundingBox(
                        coordinates=box.bbox  # [x1, y1, x2, y2, ...]
                    )
                )
                response.text_boxes.append(text_box)

            # 5. ë©”íƒ€ë°ì´í„°
            for key, value in result.metadata.items():
                response.metadata.data[key] = str(value)

            logger.info(f"OCR ì™„ë£Œ: {len(response.text_boxes)} í…ìŠ¤íŠ¸ ë°•ìŠ¤")
            return response

        except Exception as e:
            logger.error(f"OCR ì‹¤íŒ¨: {str(e)}")

            # ì—ëŸ¬ ì‘ë‹µ
            return ocr_pb2.OCRResponse(
                status=common_pb2.STATUS_FAILURE,
                error=common_pb2.ErrorInfo(
                    code="OCR_ERROR",
                    message=str(e),
                    details=type(e).__name__
                )
            )

    async def ExtractTextBatch(
        self,
        request: ocr_pb2.OCRBatchRequest,
        context: grpc.aio.ServicerContext
    ):
        """ë°°ì¹˜ ì´ë¯¸ì§€ OCR ì¶”ì¶œ (Server Streaming)

        Args:
            request: ë°°ì¹˜ ìš”ì²­
            context: gRPC ì»¨í…ìŠ¤íŠ¸

        Yields:
            ì§„í–‰ ìƒí™© ìŠ¤íŠ¸ë¦¼
        """
        import uuid

        batch_id = str(uuid.uuid4())
        total = len(request.image_paths)

        logger.info(f"ë°°ì¹˜ OCR ì‹œì‘: {batch_id}, {total}ê°œ ì´ë¯¸ì§€")

        for idx, image_path in enumerate(request.image_paths):
            # ê°œë³„ OCR ìš”ì²­ ìƒì„±
            ocr_request = ocr_pb2.OCRRequest(
                public_image_path=image_path.public_path,
                private_image_path=image_path.private_path,
                language=request.language,
                confidence_threshold=request.confidence_threshold,
                use_angle_cls=request.use_angle_cls
            )

            # OCR ì‹¤í–‰
            result = await self.ExtractText(ocr_request, context)

            # ì§„í–‰ ìƒí™© ì „ì†¡
            progress = ocr_pb2.OCRBatchProgress(
                batch_id=batch_id,
                total_images=total,
                processed_images=idx + 1,
                current_result=result,
                progress_percentage=(idx + 1) / total * 100
            )

            yield progress

        logger.info(f"ë°°ì¹˜ OCR ì™„ë£Œ: {batch_id}")

    async def CheckHealth(
        self,
        request: ocr_pb2.HealthCheckRequest,
        context: grpc.aio.ServicerContext
    ) -> ocr_pb2.HealthCheckResponse:
        """í—¬ìŠ¤ ì²´í¬

        Args:
            request: í—¬ìŠ¤ ì²´í¬ ìš”ì²­
            context: gRPC ì»¨í…ìŠ¤íŠ¸

        Returns:
            í—¬ìŠ¤ ì²´í¬ ì‘ë‹µ
        """
        from shared.config import settings

        model = get_ocr_model()

        return ocr_pb2.HealthCheckResponse(
            status=common_pb2.STATUS_SUCCESS if model.is_loaded else common_pb2.STATUS_FAILURE,
            engine_type=settings.OCR_ENGINE,
            model_loaded=model.is_loaded,
            version="1.0.0"
        )
```

### ğŸš€ gRPC ì„œë²„ ì‹œì‘

```python
# packages/ml_server/ml_app/grpc_services/server.py
"""gRPC ì„œë²„ ê´€ë¦¬"""

import asyncio
import grpc
from concurrent import futures
from grpc_reflection.v1alpha import reflection

from shared.grpc.generated import ocr_pb2_grpc
from shared.core.logging import get_logger
from shared.config import settings
from .ocr_service import OCRServiceServicer

logger = get_logger(__name__)


async def serve():
    """gRPC ì„œë²„ ì‹œì‘"""

    # 1. ì„œë²„ ìƒì„±
    server = grpc.aio.server(
        futures.ThreadPoolExecutor(max_workers=10),
        options=[
            ('grpc.max_send_message_length', 100 * 1024 * 1024),  # 100MB
            ('grpc.max_receive_message_length', 100 * 1024 * 1024),
            ('grpc.keepalive_time_ms', 10000),
            ('grpc.keepalive_timeout_ms', 5000),
        ]
    )

    # 2. ì„œë¹„ìŠ¤ ë“±ë¡
    ocr_pb2_grpc.add_OCRServiceServicer_to_server(
        OCRServiceServicer(),
        server
    )

    # 3. ë¦¬í”Œë ‰ì…˜ í™œì„±í™” (grpcurl ë“± ë””ë²„ê¹… ë„êµ¬ ì§€ì›)
    SERVICE_NAMES = (
        ocr_pb2.DESCRIPTOR.services_by_name['OCRService'].full_name,
        reflection.SERVICE_NAME,
    )
    reflection.enable_server_reflection(SERVICE_NAMES, server)

    # 4. í¬íŠ¸ ë°”ì¸ë”©
    grpc_port = settings.GRPC_PORT or 50051
    server.add_insecure_port(f'[::]:{grpc_port}')

    # 5. ì„œë²„ ì‹œì‘
    await server.start()
    logger.info(f"ğŸš€ gRPC ì„œë²„ ì‹œì‘: í¬íŠ¸ {grpc_port}")

    # 6. ì¢…ë£Œ ëŒ€ê¸°
    await server.wait_for_termination()


def start_grpc_server():
    """gRPC ì„œë²„ ì‹œì‘ (ë¸”ë¡œí‚¹)"""
    asyncio.run(serve())
```

### ğŸ”— FastAPIì™€ í†µí•©

```python
# packages/ml_server/ml_app/main.py
"""ML ì„œë²„ ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜"""

from fastapi import FastAPI
from contextlib import asynccontextmanager
import asyncio
from shared.core.logging import get_logger

logger = get_logger(__name__)


@asynccontextmanager
async def lifespan(app: FastAPI):
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒëª…ì£¼ê¸° ê´€ë¦¬"""

    # ì‹œì‘ ì‹œ
    logger.info("ML ì„œë²„ ì‹œì‘")

    # gRPC ì„œë²„ë¥¼ ë³„ë„ íƒœìŠ¤í¬ë¡œ ì‹œì‘
    from ml_app.grpc_services.server import serve
    grpc_task = asyncio.create_task(serve())

    yield

    # ì¢…ë£Œ ì‹œ
    logger.info("ML ì„œë²„ ì¢…ë£Œ")
    grpc_task.cancel()
    try:
        await grpc_task
    except asyncio.CancelledError:
        pass


app = FastAPI(lifespan=lifespan)

# REST API ë¼ìš°í„° ë“±ë¡ (ê¸°ì¡´ ìœ ì§€)
from ml_app.domains.ocr.controllers import ocr_controller
app.include_router(ocr_controller.router)
```

---

## Celery Worker êµ¬í˜„

### ğŸ“¡ gRPC í´ë¼ì´ì–¸íŠ¸

```python
# packages/celery_worker/tasks/grpc_clients/ocr_client.py
"""OCR gRPC í´ë¼ì´ì–¸íŠ¸"""

import grpc
from typing import Optional
from shared.grpc.generated import ocr_pb2, ocr_pb2_grpc
from shared.core.logging import get_logger
from shared.config import settings

logger = get_logger(__name__)


class OCRGrpcClient:
    """OCR gRPC í´ë¼ì´ì–¸íŠ¸ (ì‹±ê¸€í†¤)"""

    def __init__(self, server_address: Optional[str] = None):
        self.server_address = server_address or settings.ML_SERVER_GRPC_ADDRESS
        self._channel: Optional[grpc.aio.Channel] = None
        self._stub: Optional[ocr_pb2_grpc.OCRServiceStub] = None

    async def __aenter__(self):
        """ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì§„ì…"""
        await self.connect()
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì¢…ë£Œ"""
        await self.close()

    async def connect(self):
        """ì±„ë„ ì—°ê²°"""
        if self._channel is None:
            self._channel = grpc.aio.insecure_channel(
                self.server_address,
                options=[
                    ('grpc.max_send_message_length', 100 * 1024 * 1024),
                    ('grpc.max_receive_message_length', 100 * 1024 * 1024),
                    ('grpc.keepalive_time_ms', 10000),
                ]
            )
            self._stub = ocr_pb2_grpc.OCRServiceStub(self._channel)
            logger.info(f"gRPC ì±„ë„ ì—°ê²°: {self.server_address}")

    async def close(self):
        """ì±„ë„ ì¢…ë£Œ"""
        if self._channel:
            await self._channel.close()
            self._channel = None
            self._stub = None
            logger.info("gRPC ì±„ë„ ì¢…ë£Œ")

    async def extract_text(
        self,
        public_image_path: str,
        private_image_path: str,
        language: str = "korean",
        confidence_threshold: float = 0.5,
        use_angle_cls: bool = True,
        timeout: float = 300.0
    ) -> ocr_pb2.OCRResponse:
        """OCR í…ìŠ¤íŠ¸ ì¶”ì¶œ

        Args:
            public_image_path: ê³µê°œ ì´ë¯¸ì§€ ê²½ë¡œ
            private_image_path: ë¹„ê³µê°œ ì´ë¯¸ì§€ ê²½ë¡œ
            language: ì–¸ì–´
            confidence_threshold: ì‹ ë¢°ë„ ì„ê³„ê°’
            use_angle_cls: ê°ë„ ë¶„ë¥˜ ì‚¬ìš© ì—¬ë¶€
            timeout: íƒ€ì„ì•„ì›ƒ (ì´ˆ)

        Returns:
            OCR ì‘ë‹µ

        Raises:
            grpc.RpcError: gRPC í†µì‹  ì˜¤ë¥˜
        """
        if not self._stub:
            await self.connect()

        # ìš”ì²­ ìƒì„±
        request = ocr_pb2.OCRRequest(
            public_image_path=public_image_path,
            private_image_path=private_image_path,
            language=language,
            confidence_threshold=confidence_threshold,
            use_angle_cls=use_angle_cls
        )

        # gRPC í˜¸ì¶œ
        try:
            response = await self._stub.ExtractText(
                request,
                timeout=timeout
            )

            logger.info(
                f"gRPC OCR ì™„ë£Œ: {len(response.text_boxes)} í…ìŠ¤íŠ¸ ë°•ìŠ¤, "
                f"ì‹ ë¢°ë„: {response.overall_confidence:.2f}"
            )

            return response

        except grpc.RpcError as e:
            logger.error(f"gRPC ì˜¤ë¥˜: {e.code()}, {e.details()}")
            raise

    async def check_health(self) -> ocr_pb2.HealthCheckResponse:
        """í—¬ìŠ¤ ì²´í¬

        Returns:
            í—¬ìŠ¤ ì²´í¬ ì‘ë‹µ
        """
        if not self._stub:
            await self.connect()

        request = ocr_pb2.HealthCheckRequest(service_name="OCRService")
        return await self._stub.CheckHealth(request)


# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
_grpc_client: Optional[OCRGrpcClient] = None


def get_ocr_grpc_client() -> OCRGrpcClient:
    """OCR gRPC í´ë¼ì´ì–¸íŠ¸ ê°€ì ¸ì˜¤ê¸° (ì‹±ê¸€í†¤)"""
    global _grpc_client
    if _grpc_client is None:
        _grpc_client = OCRGrpcClient()
    return _grpc_client
```

### ğŸ”„ OCRStage ìˆ˜ì • (Dual Mode)

```python
# packages/celery_worker/tasks/stages/ocr_stage.py
"""OCR ì²˜ë¦¬ ìŠ¤í…Œì´ì§€ (HTTP + gRPC ì§€ì›)"""

import os
import httpx
import grpc
from shared.core.logging import get_logger
from shared.pipeline.context import OCRResult, PipelineContext
from shared.pipeline.exceptions import RetryableError
from shared.pipeline.stage import PipelineStage
from shared.grpc.generated import common_pb2

logger = get_logger(__name__)

# Feature Flag
USE_GRPC = os.getenv("USE_GRPC", "false").lower() == "true"


class OCRStage(PipelineStage):
    """OCR ì²˜ë¦¬ ìŠ¤í…Œì´ì§€ (HTTP/gRPC ë“€ì–¼ ëª¨ë“œ)"""

    def __init__(self):
        super().__init__()
        self.ml_server_url = settings.MODEL_SERVER_URL

    async def execute(self, context: PipelineContext) -> PipelineContext:
        """ML ì„œë²„ì— OCR ìš”ì²­ (HTTP ë˜ëŠ” gRPC)"""

        if USE_GRPC:
            return await self._execute_grpc(context)
        else:
            return await self._execute_http(context)

    async def _execute_http(self, context: PipelineContext) -> PipelineContext:
        """HTTPë¡œ OCR ì‹¤í–‰ (ê¸°ì¡´ ë°©ì‹)"""
        try:
            async with httpx.AsyncClient(timeout=300.0) as client:
                response = await client.post(
                    f"{self.ml_server_url}/ocr/extract",
                    json={
                        "public_image_path": context.public_file_path,
                        "private_image_path": context.input_file_path,
                    },
                )
                response.raise_for_status()

            ocr_data = response.json()

            context.ocr_result = OCRResult(
                text=ocr_data.get("text", ""),
                confidence=ocr_data.get("confidence", 0.0),
                bbox=ocr_data.get("text_boxes"),
                metadata=ocr_data.get("metadata", {}),
            )

            logger.info("HTTP OCR ì™„ë£Œ")
            return context

        except (httpx.TimeoutException, httpx.NetworkError) as e:
            raise RetryableError("OCRStage", f"HTTP error: {str(e)}") from e

    async def _execute_grpc(self, context: PipelineContext) -> PipelineContext:
        """gRPCë¡œ OCR ì‹¤í–‰ (ì‹ ê·œ ë°©ì‹)"""
        from tasks.grpc_clients.ocr_client import get_ocr_grpc_client

        try:
            # gRPC í´ë¼ì´ì–¸íŠ¸ ê°€ì ¸ì˜¤ê¸°
            client = get_ocr_grpc_client()

            # gRPC í˜¸ì¶œ
            response = await client.extract_text(
                public_image_path=context.public_file_path,
                private_image_path=context.input_file_path,
                language="korean",
                confidence_threshold=0.5,
                use_angle_cls=True
            )

            # ì„±ê³µ ì—¬ë¶€ í™•ì¸
            if response.status != common_pb2.STATUS_SUCCESS:
                error_msg = response.error.message if response.error else "Unknown error"
                raise ValueError(f"OCR failed: {error_msg}")

            # Protobuf â†’ OCRResult ë³€í™˜
            text_boxes = [
                {
                    "text": box.text,
                    "confidence": box.confidence,
                    "bbox": list(box.bbox.coordinates)
                }
                for box in response.text_boxes
            ]

            context.ocr_result = OCRResult(
                text=response.text,
                confidence=response.overall_confidence,
                bbox=text_boxes,
                metadata=dict(response.metadata.data)
            )

            logger.info("gRPC OCR ì™„ë£Œ")
            return context

        except grpc.RpcError as e:
            # gRPC ì˜¤ë¥˜ ì²˜ë¦¬
            if e.code() in [grpc.StatusCode.UNAVAILABLE, grpc.StatusCode.DEADLINE_EXCEEDED]:
                # ì¬ì‹œë„ ê°€ëŠ¥í•œ ì˜¤ë¥˜
                raise RetryableError("OCRStage", f"gRPC error: {e.details()}") from e
            else:
                # ì¬ì‹œë„ ë¶ˆê°€ëŠ¥í•œ ì˜¤ë¥˜
                raise ValueError(f"gRPC OCR failed: {e.details()}") from e
```

---

## ë°°í¬ ë° ì „í™˜ ì „ëµ

### ğŸ“‹ Proto íŒŒì¼ ì»´íŒŒì¼

```bash
# packages/shared/Makefile
.PHONY: generate-grpc
generate-grpc:
	python -m grpc_tools.protoc \
		-I./shared/grpc/protos \
		--python_out=./shared/grpc/generated \
		--grpc_python_out=./shared/grpc/generated \
		--pyi_out=./shared/grpc/generated \
		./shared/grpc/protos/*.proto

	# __init__.py ìƒì„±
	touch ./shared/grpc/generated/__init__.py

	echo "âœ… gRPC ì½”ë“œ ìƒì„± ì™„ë£Œ"
```

```bash
# ì‹¤í–‰
cd packages/shared
make generate-grpc
```

### ğŸš€ í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

```bash
# .env
# ML Server
GRPC_PORT=50051

# Celery Worker
ML_SERVER_GRPC_ADDRESS=ml_server:50051  # Docker í™˜ê²½
USE_GRPC=true  # gRPC í™œì„±í™”
```

### ğŸ³ Docker Compose ìˆ˜ì •

```yaml
# docker-compose.yml
services:
  ml_server:
    ports:
      - "8001:8000"  # FastAPI (HTTP)
      - "50051:50051"  # gRPC
    environment:
      - GRPC_PORT=50051

  celery_worker:
    environment:
      - ML_SERVER_GRPC_ADDRESS=ml_server:50051
      - USE_GRPC=true
    depends_on:
      - ml_server
```

### ğŸ“Š ë‹¨ê³„ë³„ ì „í™˜

#### Phase 1: ê°œë°œ í™˜ê²½ì—ì„œ í…ŒìŠ¤íŠ¸
```bash
# gRPC í™œì„±í™”
export USE_GRPC=true

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
pytest tests/test_grpc_ocr.py -v
```

#### Phase 2: ì¹´ë‚˜ë¦¬ ë°°í¬ (10% íŠ¸ë˜í”½)
```python
# í™•ë¥  ê¸°ë°˜ ë¶„ê¸°
import random

USE_GRPC = random.random() < 0.1  # 10% íŠ¸ë˜í”½ë§Œ gRPC
```

#### Phase 3: ì ì§„ì  ì¦ê°€
```
Week 1: 10% gRPC
Week 2: 50% gRPC
Week 3: 90% gRPC
Week 4: 100% gRPC (HTTPëŠ” í´ë°±ë§Œ)
```

---

## ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬

### ğŸ¯ ì¸¡ì • ì§€í‘œ

```python
# packages/shared/shared/utils/benchmark.py
"""ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ìœ í‹¸ë¦¬í‹°"""

import time
import asyncio
from typing import Callable
from shared.core.logging import get_logger

logger = get_logger(__name__)


async def benchmark_ocr(
    method: str,  # "http" or "grpc"
    iterations: int = 100,
    image_path: str = "test.jpg"
):
    """OCR ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬

    Args:
        method: í†µì‹  ë°©ì‹
        iterations: ë°˜ë³µ íšŸìˆ˜
        image_path: í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ê²½ë¡œ
    """

    latencies = []

    for i in range(iterations):
        start = time.time()

        if method == "http":
            # HTTP í˜¸ì¶œ
            import httpx
            async with httpx.AsyncClient() as client:
                await client.post(
                    "http://ml_server:8000/ocr/extract",
                    json={"private_image_path": image_path}
                )
        else:
            # gRPC í˜¸ì¶œ
            from tasks.grpc_clients.ocr_client import get_ocr_grpc_client
            client = get_ocr_grpc_client()
            await client.extract_text(
                public_image_path=image_path,
                private_image_path=image_path
            )

        latency = (time.time() - start) * 1000  # ms
        latencies.append(latency)

        if (i + 1) % 10 == 0:
            logger.info(f"ì§„í–‰: {i + 1}/{iterations}")

    # í†µê³„
    avg_latency = sum(latencies) / len(latencies)
    p50 = sorted(latencies)[len(latencies) // 2]
    p95 = sorted(latencies)[int(len(latencies) * 0.95)]
    p99 = sorted(latencies)[int(len(latencies) * 0.99)]

    logger.info(f"""
    === {method.upper()} ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ===
    ë°˜ë³µ: {iterations}
    í‰ê·  ì§€ì—°: {avg_latency:.2f}ms
    P50: {p50:.2f}ms
    P95: {p95:.2f}ms
    P99: {p99:.2f}ms
    """)

    return {
        "method": method,
        "avg": avg_latency,
        "p50": p50,
        "p95": p95,
        "p99": p99
    }
```

### ğŸ“ˆ ì˜ˆìƒ ì„±ëŠ¥ ê°œì„ 

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Metric      â”‚   HTTP   â”‚   gRPC   â”‚ ê°œì„ ìœ¨   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ í‰ê·  ì§€ì—° (ms)   â”‚   150    â”‚    90    â”‚  -40%   â”‚
â”‚ P95 ì§€ì—° (ms)    â”‚   250    â”‚   140    â”‚  -44%   â”‚
â”‚ ì²˜ë¦¬ëŸ‰ (req/s)   â”‚   200    â”‚   350    â”‚  +75%   â”‚
â”‚ ë©”ì‹œì§€ í¬ê¸° (KB) â”‚    2.5   â”‚    1.8   â”‚  -28%   â”‚
â”‚ CPU ì‚¬ìš©ë¥  (%)   â”‚    45    â”‚    35    â”‚  -22%   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ë¬¸ì œ í•´ê²° ê°€ì´ë“œ

### âŒ ë¬¸ì œ 1: Proto ì»´íŒŒì¼ ì˜¤ë¥˜

**ì¦ìƒ**:
```
ModuleNotFoundError: No module named 'shared.grpc.generated.ocr_pb2'
```

**í•´ê²°**:
```bash
# Proto ì¬ì»´íŒŒì¼
cd packages/shared
make generate-grpc

# ìƒì„± í™•ì¸
ls shared/grpc/generated/
# â†’ ocr_pb2.py, ocr_pb2_grpc.py ì¡´ì¬í•´ì•¼ í•¨
```

### âŒ ë¬¸ì œ 2: gRPC ì±„ë„ ì—°ê²° ì‹¤íŒ¨

**ì¦ìƒ**:
```
grpc.RpcError: StatusCode.UNAVAILABLE, failed to connect to all addresses
```

**í•´ê²°**:
```python
# 1. ML Server gRPC ì„œë²„ í™•ì¸
curl http://ml_server:8000/healthy  # FastAPIëŠ” ì‘ë™í•˜ëŠ”ì§€

# 2. í¬íŠ¸ í™•ì¸
docker ps | grep ml_server
# â†’ 50051 í¬íŠ¸ ë…¸ì¶œ í™•ì¸

# 3. ì£¼ì†Œ í™•ì¸
# ml_server:50051 (Docker)
# localhost:50051 (ë¡œì»¬)
```

### âŒ ë¬¸ì œ 3: ë©”ì‹œì§€ í¬ê¸° ì´ˆê³¼

**ì¦ìƒ**:
```
grpc.RpcError: StatusCode.RESOURCE_EXHAUSTED, Received message larger than max
```

**í•´ê²°**:
```python
# í´ë¼ì´ì–¸íŠ¸/ì„œë²„ ëª¨ë‘ ë©”ì‹œì§€ í¬ê¸° ì¦ê°€
options=[
    ('grpc.max_send_message_length', 100 * 1024 * 1024),  # 100MB
    ('grpc.max_receive_message_length', 100 * 1024 * 1024),
]
```

### âŒ ë¬¸ì œ 4: íƒ€ì„ì•„ì›ƒ

**ì¦ìƒ**:
```
grpc.RpcError: StatusCode.DEADLINE_EXCEEDED
```

**í•´ê²°**:
```python
# íƒ€ì„ì•„ì›ƒ ì¦ê°€
await stub.ExtractText(request, timeout=600.0)  # 10ë¶„

# Keep-alive ì„¤ì •
options=[
    ('grpc.keepalive_time_ms', 10000),
    ('grpc.keepalive_timeout_ms', 5000),
]
```

---

## í…ŒìŠ¤íŠ¸ ì „ëµ

### ğŸ§ª ë‹¨ìœ„ í…ŒìŠ¤íŠ¸

```python
# tests/test_grpc_ocr.py
"""gRPC OCR í…ŒìŠ¤íŠ¸"""

import pytest
from shared.grpc.generated import ocr_pb2, common_pb2
from ml_app.grpc_services.ocr_service import OCRServiceServicer


@pytest.mark.asyncio
async def test_extract_text_success():
    """OCR ì¶”ì¶œ ì„±ê³µ í…ŒìŠ¤íŠ¸"""

    # Given
    servicer = OCRServiceServicer()
    request = ocr_pb2.OCRRequest(
        public_image_path="test.jpg",
        private_image_path="/data/test.jpg",
        language="korean",
        confidence_threshold=0.5,
        use_angle_cls=True
    )

    # When
    response = await servicer.ExtractText(request, None)

    # Then
    assert response.status == common_pb2.STATUS_SUCCESS
    assert len(response.text) > 0
    assert response.overall_confidence > 0


@pytest.mark.asyncio
async def test_extract_text_failure():
    """OCR ì¶”ì¶œ ì‹¤íŒ¨ í…ŒìŠ¤íŠ¸ (ì˜ëª»ëœ ê²½ë¡œ)"""

    # Given
    servicer = OCRServiceServicer()
    request = ocr_pb2.OCRRequest(
        private_image_path="/invalid/path.jpg"
    )

    # When
    response = await servicer.ExtractText(request, None)

    # Then
    assert response.status == common_pb2.STATUS_FAILURE
    assert response.error.code == "OCR_ERROR"
```

### ğŸ”¬ í†µí•© í…ŒìŠ¤íŠ¸

```python
# tests/integration/test_grpc_integration.py
"""gRPC í†µí•© í…ŒìŠ¤íŠ¸"""

import pytest
import grpc
from shared.grpc.generated import ocr_pb2, ocr_pb2_grpc


@pytest.mark.asyncio
async def test_end_to_end_grpc():
    """End-to-End gRPC í…ŒìŠ¤íŠ¸"""

    # Given: gRPC ì±„ë„ ì—°ê²°
    async with grpc.aio.insecure_channel('localhost:50051') as channel:
        stub = ocr_pb2_grpc.OCRServiceStub(channel)

        request = ocr_pb2.OCRRequest(
            private_image_path="/data/sample.jpg"
        )

        # When: OCR ì‹¤í–‰
        response = await stub.ExtractText(request)

        # Then: ê²°ê³¼ ê²€ì¦
        assert response.status == ocr_pb2.STATUS_SUCCESS
        assert len(response.text_boxes) > 0
```

---

## ë§ˆì´ê·¸ë ˆì´ì…˜ ì²´í¬ë¦¬ìŠ¤íŠ¸

### âœ… Phase 1: ì¤€ë¹„ (1ì£¼)
- [ ] Proto íŒŒì¼ ì •ì˜ ì™„ë£Œ
- [ ] `grpcio`, `grpcio-tools` ì„¤ì¹˜
- [ ] Proto ì»´íŒŒì¼ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±
- [ ] gRPC ì„œë¹„ìŠ¤ ìŠ¤ì¼ˆë ˆí†¤ êµ¬í˜„
- [ ] ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„±

### âœ… Phase 2: êµ¬í˜„ (2ì£¼)
- [ ] ML Server gRPC ì„œë¹„ìŠ¤ êµ¬í˜„
- [ ] Celery Worker gRPC í´ë¼ì´ì–¸íŠ¸ êµ¬í˜„
- [ ] Dual Mode ì§€ì› (Feature Flag)
- [ ] ì—ëŸ¬ í•¸ë“¤ë§ ë° ì¬ì‹œë„ ë¡œì§
- [ ] ë¡œê¹… ë° ëª¨ë‹ˆí„°ë§ ì¶”ê°€

### âœ… Phase 3: í…ŒìŠ¤íŠ¸ (1ì£¼)
- [ ] ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ í†µê³¼
- [ ] í†µí•© í…ŒìŠ¤íŠ¸ í†µê³¼
- [ ] ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ì™„ë£Œ
- [ ] ë¶€í•˜ í…ŒìŠ¤íŠ¸ (100+ ë™ì‹œ ìš”ì²­)
- [ ] ì¥ì•  ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸

### âœ… Phase 4: ë°°í¬ (1ì£¼)
- [ ] ê°œë°œ í™˜ê²½ ë°°í¬
- [ ] ìŠ¤í…Œì´ì§• í™˜ê²½ í…ŒìŠ¤íŠ¸
- [ ] ì¹´ë‚˜ë¦¬ ë°°í¬ (10% íŠ¸ë˜í”½)
- [ ] ì ì§„ì  ì¦ê°€ (50% â†’ 90% â†’ 100%)
- [ ] HTTP í´ë°± ì œê±°

---

## ì°¸ê³  ìë£Œ

### ğŸ“š ê³µì‹ ë¬¸ì„œ
- [gRPC Python Quickstart](https://grpc.io/docs/languages/python/quickstart/)
- [Protocol Buffers Guide](https://developers.google.com/protocol-buffers/docs/pythontutorial)
- [gRPC Performance Best Practices](https://grpc.io/docs/guides/performance/)

### ğŸ› ï¸ ë””ë²„ê¹… ë„êµ¬
```bash
# grpcurl ì„¤ì¹˜ (macOS)
brew install grpcurl

# ì„œë¹„ìŠ¤ ëª©ë¡ í™•ì¸
grpcurl -plaintext localhost:50051 list

# ë©”ì„œë“œ í˜¸ì¶œ
grpcurl -plaintext -d '{"private_image_path": "/data/test.jpg"}' \
    localhost:50051 ocr.OCRService/ExtractText
```

### ğŸ“Š ëª¨ë‹ˆí„°ë§
```python
# Prometheus ë©”íŠ¸ë¦­ ì¶”ê°€
from prometheus_client import Counter, Histogram

grpc_requests_total = Counter(
    'grpc_requests_total',
    'Total gRPC requests',
    ['method', 'status']
)

grpc_request_duration = Histogram(
    'grpc_request_duration_seconds',
    'gRPC request duration',
    ['method']
)
```

---

## ê²°ë¡ 

gRPC ë§ˆì´ê·¸ë ˆì´ì…˜ì„ í†µí•´ ë‹¤ìŒê³¼ ê°™ì€ ê°œì„ ì„ ê¸°ëŒ€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

1. **ì„±ëŠ¥**: 40-50% ì§€ì—° ì‹œê°„ ê°ì†Œ
2. **ì²˜ë¦¬ëŸ‰**: 70-100% ì¦ê°€
3. **íƒ€ì… ì•ˆì „ì„±**: ì»´íŒŒì¼ íƒ€ì„ ê²€ì¦
4. **í™•ì¥ì„±**: ìŠ¤íŠ¸ë¦¬ë°, ì–‘ë°©í–¥ í†µì‹  ì§€ì›

ë‹¨ê³„ì  ë§ˆì´ê·¸ë ˆì´ì…˜(Strangler Fig Pattern)ì„ í†µí•´ **ë¦¬ìŠ¤í¬ë¥¼ ìµœì†Œí™”**í•˜ë©´ì„œ ì•ˆì •ì ìœ¼ë¡œ ì „í™˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
