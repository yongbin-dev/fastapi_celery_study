# gRPC ì„¤ì • ë° ì‚¬ìš© ê°€ì´ë“œ

## ğŸ“‹ ì„¤ì • ì™„ë£Œ ì‚¬í•­

### âœ… 1. Proto íŒŒì¼
- `packages/shared/shared/grpc/protos/common.proto` - ê³µí†µ íƒ€ì… ì •ì˜
- `packages/shared/shared/grpc/protos/ocr.proto` - OCR ì„œë¹„ìŠ¤ ì •ì˜

### âœ… 2. ìƒì„±ëœ Python ì½”ë“œ
- `packages/shared/shared/grpc/generated/common_pb2.py`
- `packages/shared/shared/grpc/generated/ocr_pb2.py`
- `packages/shared/shared/grpc/generated/ocr_pb2_grpc.py`

### âœ… 3. ML Server gRPC ì„œë¹„ìŠ¤
- `packages/ml_server/ml_app/grpc_services/ocr_service.py` - OCR gRPC ì„œë¹„ìŠ¤ êµ¬í˜„
- `packages/ml_server/ml_app/grpc_services/server.py` - gRPC ì„œë²„
- `packages/ml_server/ml_app/main.py` - FastAPI + gRPC í†µí•©

### âœ… 4. Celery Worker gRPC í´ë¼ì´ì–¸íŠ¸
- `packages/celery_worker/tasks/grpc_clients/ocr_client.py` - OCR gRPC í´ë¼ì´ì–¸íŠ¸
- `packages/celery_worker/tasks/stages/ocr_stage.py` - Dual Mode ì§€ì›

---

## ğŸš€ ì‹œì‘í•˜ê¸°

### 1. Proto íŒŒì¼ ì»´íŒŒì¼ (í•„ìš” ì‹œ)

Proto íŒŒì¼ì„ ìˆ˜ì •í•œ ê²½ìš° ì¬ì»´íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤:

```bash
# monorepo ë£¨íŠ¸ì—ì„œ ì‹¤í–‰
uvx --from grpcio-tools==1.68.1 python -m grpc_tools.protoc \
  -I./packages/shared/shared/grpc/protos \
  --python_out=./packages/shared/shared/grpc/generated \
  --grpc_python_out=./packages/shared/shared/grpc/generated \
  --pyi_out=./packages/shared/shared/grpc/generated \
  ./packages/shared/shared/grpc/protos/*.proto
```

ë˜ëŠ” Makefile ì‚¬ìš©:
```bash
cd packages/shared
make generate-grpc
```

### 2. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

#### ML Server (.env ë˜ëŠ” í™˜ê²½ ë³€ìˆ˜)
```bash
# gRPC ì„œë²„ í¬íŠ¸
GRPC_PORT=50051

# gRPC í™œì„±í™”
USE_GRPC=true
```

#### Celery Worker (.env ë˜ëŠ” í™˜ê²½ ë³€ìˆ˜)
```bash
# ML Server gRPC ì£¼ì†Œ
ML_SERVER_GRPC_ADDRESS=localhost:50051  # ë¡œì»¬
# ML_SERVER_GRPC_ADDRESS=ml_server:50051  # Docker

# gRPC ì‚¬ìš© ì—¬ë¶€
USE_GRPC=true
```

### 3. ML Server ì‹¤í–‰

```bash
# HTTPë§Œ (ê¸°ë³¸ê°’)
cd packages/ml_server
uv run uvicorn ml_app.main:app --host 0.0.0.0 --port 8000

# HTTP + gRPC
USE_GRPC=true GRPC_PORT=50051 uv run uvicorn ml_app.main:app --host 0.0.0.0 --port 8000
```

ë¡œê·¸ í™•ì¸:
```
ğŸš€ ML ì„œë²„ ì‹œì‘
âœ… gRPC ì„œë²„ íƒœìŠ¤í¬ ì‹œì‘
ğŸš€ gRPC ì„œë²„ ì‹œì‘: í¬íŠ¸ 50051
```

### 4. Celery Worker ì‹¤í–‰

```bash
# HTTP ëª¨ë“œ (ê¸°ì¡´)
cd packages/celery_worker
uv run celery -A celery_app worker --loglevel=info

# gRPC ëª¨ë“œ (ì‹ ê·œ)
USE_GRPC=true ML_SERVER_GRPC_ADDRESS=localhost:50051 \
  uv run celery -A celery_app worker --loglevel=info
```

---

## ğŸ§ª í…ŒìŠ¤íŠ¸

### 1. gRPC ì„œë²„ í—¬ìŠ¤ ì²´í¬ (grpcurl ì‚¬ìš©)

```bash
# grpcurl ì„¤ì¹˜ (macOS)
brew install grpcurl

# ì„œë¹„ìŠ¤ ëª©ë¡ í™•ì¸
grpcurl -plaintext localhost:50051 list

# í—¬ìŠ¤ ì²´í¬
grpcurl -plaintext localhost:50051 ocr.OCRService/CheckHealth
```

ì˜ˆìƒ ì¶œë ¥:
```json
{
  "status": "STATUS_SUCCESS",
  "engineType": "mock",
  "modelLoaded": true,
  "version": "1.0.0"
}
```

### 2. Python ìŠ¤í¬ë¦½íŠ¸ë¡œ í…ŒìŠ¤íŠ¸

```python
# test_grpc_ocr.py
import asyncio
from tasks.grpc_clients.ocr_client import OCRGrpcClient

async def test_ocr():
    client = OCRGrpcClient("localhost:50051")

    try:
        # í—¬ìŠ¤ ì²´í¬
        health = await client.check_health()
        print(f"Health: {health.status}, Engine: {health.engine_type}")

        # OCR ì¶”ì¶œ
        response = await client.extract_text(
            public_image_path="/test/image.jpg",
            private_image_path="/data/test.jpg"
        )

        print(f"Status: {response.status}")
        print(f"Text boxes: {len(response.text_boxes)}")
        print(f"Overall confidence: {response.overall_confidence:.2f}")

    finally:
        await client.close()

if __name__ == "__main__":
    asyncio.run(test_ocr())
```

### 3. íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸

```python
# HTTP ëª¨ë“œë¡œ ì‹¤í–‰
import os
os.environ["USE_GRPC"] = "false"

# ë˜ëŠ” gRPC ëª¨ë“œë¡œ ì‹¤í–‰
os.environ["USE_GRPC"] = "true"
os.environ["ML_SERVER_GRPC_ADDRESS"] = "localhost:50051"

# íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
from tasks.pipeline_tasks import start_pipeline
from shared.schemas.common import ImageResponse

image_response = ImageResponse(
    public_img="/test/image.jpg",
    private_img="/data/test.jpg"
)

context_id = start_pipeline(image_response, "batch_123", {})
print(f"Pipeline started: {context_id}")
```

---

## ğŸ“Š ëª¨ë“œ ì „í™˜

### HTTP â†’ gRPC ì „í™˜ ë‹¨ê³„

1. **ê°œë°œ í™˜ê²½ í…ŒìŠ¤íŠ¸**
   ```bash
   USE_GRPC=true uv run uvicorn ml_app.main:app
   USE_GRPC=true uv run celery -A celery_app worker
   ```

2. **ë¡œê·¸ í™•ì¸**
   ```
   # ML Server ë¡œê·¸
   âœ… gRPC ì„œë²„ íƒœìŠ¤í¬ ì‹œì‘
   ğŸš€ gRPC ì„œë²„ ì‹œì‘: í¬íŠ¸ 50051

   # Celery Worker ë¡œê·¸
   gRPC ëª¨ë“œë¡œ OCR ì‹¤í–‰
   gRPC ì±„ë„ ì—°ê²°: localhost:50051
   gRPC OCR ì™„ë£Œ: 10 í…ìŠ¤íŠ¸ ë°•ìŠ¤
   ```

3. **ì ì§„ì  ë°°í¬**
   - Week 1: ê°œë°œ í™˜ê²½ í…ŒìŠ¤íŠ¸
   - Week 2: ìŠ¤í…Œì´ì§• í™˜ê²½ (10% íŠ¸ë˜í”½)
   - Week 3: í”„ë¡œë•ì…˜ (50% íŠ¸ë˜í”½)
   - Week 4: í”„ë¡œë•ì…˜ (100% íŠ¸ë˜í”½)

---

## ğŸ”§ ë””ë²„ê¹…

### gRPC ì„œë²„ê°€ ì‹œì‘ë˜ì§€ ì•ŠëŠ” ê²½ìš°

```bash
# í¬íŠ¸ ì‚¬ìš© í™•ì¸
lsof -i :50051

# grpcio ë²„ì „ í™•ì¸
pip list | grep grpcio

# ë¡œê·¸ ë ˆë²¨ ì¦ê°€
USE_GRPC=true LOG_LEVEL=DEBUG uv run uvicorn ml_app.main:app
```

### gRPC í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì‹¤íŒ¨

```bash
# ë„¤íŠ¸ì›Œí¬ ì—°ê²° í™•ì¸
nc -zv localhost 50051

# grpcurlë¡œ ì§ì ‘ í…ŒìŠ¤íŠ¸
grpcurl -plaintext localhost:50051 ocr.OCRService/CheckHealth

# íƒ€ì„ì•„ì›ƒ ì¦ê°€
# ocr_client.pyì—ì„œ timeout íŒŒë¼ë¯¸í„° ì¡°ì •
```

### Proto íŒŒì¼ ìˆ˜ì • í›„ ë°˜ì˜ ì•ˆ ë¨

```bash
# ìƒì„±ëœ íŒŒì¼ ì‚­ì œ
rm packages/shared/shared/grpc/generated/*.py
rm packages/shared/shared/grpc/generated/*.pyi

# ì¬ì»´íŒŒì¼
cd packages/shared
make generate-grpc

# Python ìºì‹œ ì‚­ì œ
find . -type d -name "__pycache__" -exec rm -rf {} +
find . -type f -name "*.pyc" -delete
```

---

## ğŸ“ˆ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

### ì§€ì—° ì‹œê°„ ì¸¡ì •

```python
import time

# HTTP
start = time.time()
# ... HTTP ìš”ì²­
http_latency = (time.time() - start) * 1000

# gRPC
start = time.time()
# ... gRPC ìš”ì²­
grpc_latency = (time.time() - start) * 1000

print(f"HTTP: {http_latency:.2f}ms, gRPC: {grpc_latency:.2f}ms")
```

### ì˜ˆìƒ ì„±ëŠ¥

| ì§€í‘œ | HTTP | gRPC | ê°œì„  |
|------|------|------|------|
| í‰ê·  ì§€ì—° | 150ms | 90ms | -40% |
| P95 ì§€ì—° | 250ms | 140ms | -44% |
| ì²˜ë¦¬ëŸ‰ | 200 req/s | 350 req/s | +75% |

---

## ğŸ” ë³´ì•ˆ ê³ ë ¤ì‚¬í•­

í˜„ì¬ êµ¬í˜„ì€ **insecure channel** (ì•”í˜¸í™” ì—†ìŒ)ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œëŠ” TLS ì ìš© ê¶Œì¥:

```python
# ì„œë²„
credentials = grpc.ssl_server_credentials(
    [(server_key, server_cert)]
)
server.add_secure_port(f'[::]:{grpc_port}', credentials)

# í´ë¼ì´ì–¸íŠ¸
credentials = grpc.ssl_channel_credentials(
    root_certificates=ca_cert,
    private_key=client_key,
    certificate_chain=client_cert
)
channel = grpc.aio.secure_channel(
    server_address,
    credentials
)
```

---

## ğŸ“ ì£¼ìš” ì°¨ì´ì  ìš”ì•½

| í•­ëª© | HTTP | gRPC |
|------|------|------|
| í”„ë¡œí† ì½œ | HTTP/1.1 | HTTP/2 |
| ì§ë ¬í™” | JSON | Protobuf |
| íƒ€ì… ì•ˆì •ì„± | ëŸ°íƒ€ì„ | ì»´íŒŒì¼ íƒ€ì„ |
| ìŠ¤íŠ¸ë¦¬ë° | ì œí•œì  | ì–‘ë°©í–¥ ì§€ì› |
| ì„±ëŠ¥ | í‘œì¤€ | 40-50% ë¹ ë¦„ |
| ë””ë²„ê¹… | ì‰¬ì›€ | grpcurl í•„ìš” |

---

## ğŸ¯ ë‹¤ìŒ ë‹¨ê³„

1. âœ… **ê¸°ë³¸ êµ¬í˜„ ì™„ë£Œ**
   - Proto íŒŒì¼ ì •ì˜
   - ML Server gRPC ì„œë¹„ìŠ¤
   - Celery Worker gRPC í´ë¼ì´ì–¸íŠ¸
   - Dual Mode ì§€ì›

2. ğŸ”„ **ì¶”ê°€ ê°œì„  ì‚¬í•­** (ì„ íƒ)
   - LLM gRPC ì„œë¹„ìŠ¤ ì¶”ê°€
   - TLS ë³´ì•ˆ ì ìš©
   - ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬
   - ëª¨ë‹ˆí„°ë§ ë©”íŠ¸ë¦­ ì¶”ê°€
   - gRPC ì¸í„°ì…‰í„° (ë¡œê¹…, ì¸ì¦)

3. ğŸ“Š **ëª¨ë‹ˆí„°ë§ ë° ìµœì í™”**
   - Prometheus ë©”íŠ¸ë¦­ ìˆ˜ì§‘
   - Grafana ëŒ€ì‹œë³´ë“œ
   - ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§
   - ì—ëŸ¬ íŠ¸ë˜í‚¹

---

## ğŸ’¡ ìœ ìš©í•œ ëª…ë ¹ì–´

```bash
# Proto ì»´íŒŒì¼
make generate-grpc

# gRPC ì„œë²„ í™•ì¸
grpcurl -plaintext localhost:50051 list

# í—¬ìŠ¤ ì²´í¬
grpcurl -plaintext localhost:50051 ocr.OCRService/CheckHealth

# ML Server ì‹¤í–‰ (gRPC)
USE_GRPC=true uv run uvicorn ml_app.main:app

# Celery Worker ì‹¤í–‰ (gRPC)
USE_GRPC=true uv run celery -A celery_app worker
```
