# ë°°ì¹˜ íŒŒì´í”„ë¼ì¸ ì‹œìŠ¤í…œ

ëŒ€ëŸ‰ ì´ë¯¸ì§€ë¥¼ ì²­í¬ ë‹¨ìœ„ë¡œ ë³‘ë ¬ ì²˜ë¦¬í•˜ëŠ” ë°°ì¹˜ íŒŒì´í”„ë¼ì¸ ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

## ğŸ“‹ ê°œìš”

ê¸°ì¡´ì˜ ë‹¨ì¼ ì´ë¯¸ì§€ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ì„ í™•ì¥í•˜ì—¬ 100ê°œ, 1000ê°œ ì´ìƒì˜ ì´ë¯¸ì§€ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” ë°°ì¹˜ ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

### ì£¼ìš” íŠ¹ì§•

- **ì²­í¬ ê¸°ë°˜ ë³‘ë ¬ ì²˜ë¦¬**: ì´ë¯¸ì§€ë¥¼ ì‘ì€ ì²­í¬(ê¸°ë³¸ 10ê°œ)ë¡œ ë¶„í• í•˜ì—¬ ë³‘ë ¬ ì²˜ë¦¬
- **ì‹¤ì‹œê°„ ì§„í–‰ ìƒí™© ì¶”ì **: ë°°ì¹˜ ì²˜ë¦¬ ì§„í–‰ë¥ , ì™„ë£Œ/ì‹¤íŒ¨ ì´ë¯¸ì§€ ìˆ˜ ì‹¤ì‹œê°„ í™•ì¸
- **ì¥ì•  ë³µêµ¬**: ì²­í¬ ë‹¨ìœ„ ì¬ì‹œë„ë¡œ ì‹¤íŒ¨ ì‹œ ìµœì†Œ ë²”ìœ„ë§Œ ì¬ì²˜ë¦¬
- **í™•ì¥ì„±**: Celeryì˜ ë¶„ì‚° ì²˜ë¦¬ë¡œ ì›Œì»¤ ì¶”ê°€ë§Œìœ¼ë¡œ ì„±ëŠ¥ í™•ì¥ ê°€ëŠ¥

## ğŸ—ï¸ ì•„í‚¤í…ì²˜

### ë°ì´í„°ë² ì´ìŠ¤ ëª¨ë¸

#### BatchExecution (ë°°ì¹˜ ì‹¤í–‰)
```python
- batch_id: ë°°ì¹˜ ê³ ìœ  ID (UUID)
- batch_name: ë°°ì¹˜ ì´ë¦„
- total_images: ì´ ì´ë¯¸ì§€ ìˆ˜
- completed_images: ì™„ë£Œëœ ì´ë¯¸ì§€ ìˆ˜
- failed_images: ì‹¤íŒ¨í•œ ì´ë¯¸ì§€ ìˆ˜
- total_chunks: ì´ ì²­í¬ ìˆ˜
- completed_chunks: ì™„ë£Œëœ ì²­í¬ ìˆ˜
- chunk_size: ì²­í¬ë‹¹ ì´ë¯¸ì§€ ìˆ˜
```

#### ChainExecution (ê°œë³„ íŒŒì´í”„ë¼ì¸)
```python
- batch_id: ì—°ê²°ëœ ë°°ì¹˜ ID (nullable)
```

### íƒœìŠ¤í¬ êµ¬ì¡°

```
start_batch_pipeline()
  â”œâ”€ BatchExecution ìƒì„±
  â”œâ”€ íŒŒì¼ ê²½ë¡œë¥¼ ì²­í¬ë¡œ ë¶„í• 
  â””â”€ Celery groupìœ¼ë¡œ ë³‘ë ¬ ì‹¤í–‰
      â”œâ”€ process_chunk_task(chunk_0)
      â”‚   â””â”€ start_pipeline() Ã— N
      â”œâ”€ process_chunk_task(chunk_1)
      â”‚   â””â”€ start_pipeline() Ã— N
      â””â”€ process_chunk_task(chunk_N)
          â””â”€ start_pipeline() Ã— N
```

## ğŸš€ ì‚¬ìš© ë°©ë²•

### 1. DB ë§ˆì´ê·¸ë ˆì´ì…˜

```bash
# PostgreSQLì— ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰
psql -U your_user -d your_database -f migrations/001_add_batch_execution.sql
```

### 2. API í˜¸ì¶œ

#### ë°°ì¹˜ íŒŒì´í”„ë¼ì¸ ì‹œì‘

```bash
curl -X POST "http://localhost:8000/pipeline/batch" \
  -H "Content-Type: multipart/form-data" \
  -F "batch_name=test_batch_001" \
  -F "files=@image1.jpg" \
  -F "files=@image2.jpg" \
  -F "files=@image3.jpg"
```

**ì‘ë‹µ:**
```json
{
  "success": true,
  "data": {
    "context_id": "550e8400-e29b-41d4-a716-446655440000",
    "message": "ë°°ì¹˜ íŒŒì´í”„ë¼ì¸ ì‹œì‘ë¨: 100ê°œ ì´ë¯¸ì§€"
  }
}
```

#### ë°°ì¹˜ ìƒíƒœ ì¡°íšŒ

```bash
curl "http://localhost:8000/pipeline/batch/{batch_id}"
```

**ì‘ë‹µ:**
```json
{
  "success": true,
  "data": {
    "batch_id": "550e8400-e29b-41d4-a716-446655440000",
    "status": "STARTED",
    "total_images": 100,
    "completed_images": 45,
    "failed_images": 2,
    "progress_percentage": 47.0,
    "started_at": "2025-01-15T10:30:00",
    "estimated_time_remaining": 120.5
  }
}
```

#### ë°°ì¹˜ ëª©ë¡ ì¡°íšŒ

```bash
curl "http://localhost:8000/pipeline/batch?limit=10"
```

## âš™ï¸ ì„¤ì •

### ì²­í¬ í¬ê¸° ì¡°ì •

ë°°ì¹˜ ì‹œì‘ ì‹œ `chunk_size` íŒŒë¼ë¯¸í„°ë¡œ ì¡°ì • ê°€ëŠ¥:

```python
# celery_worker/tasks/pipeline_tasks.py
start_batch_pipeline(
    batch_name="my_batch",
    file_paths=file_paths,
    public_file_paths=public_file_paths,
    options={},
    chunk_size=20,  # ì²­í¬ë‹¹ 20ê°œ ì´ë¯¸ì§€
)
```

**ê¶Œì¥ ì²­í¬ í¬ê¸°:**
- ì‘ì€ ì´ë¯¸ì§€ (< 1MB): 20-50ê°œ
- ì¤‘ê°„ ì´ë¯¸ì§€ (1-5MB): 10-20ê°œ
- í° ì´ë¯¸ì§€ (> 5MB): 5-10ê°œ

### Celery ì›Œì»¤ ìˆ˜ ì¡°ì •

```bash
# ì›Œì»¤ ìˆ˜ ì¦ê°€ë¡œ ì²˜ë¦¬ëŸ‰ í–¥ìƒ
celery -A celery_app worker --loglevel=info --concurrency=8
```

## ğŸ“Š ì„±ëŠ¥ ì˜ˆì¸¡

### ì²˜ë¦¬ ì‹œê°„ ì˜ˆì¸¡

```
ì´ ì²˜ë¦¬ ì‹œê°„ â‰ˆ (ì´ ì´ë¯¸ì§€ ìˆ˜ / ì²­í¬ í¬ê¸°) Ã— ì´ë¯¸ì§€ë‹¹ ì²˜ë¦¬ ì‹œê°„ / ì›Œì»¤ ìˆ˜
```

**ì˜ˆì‹œ:**
- 1000ê°œ ì´ë¯¸ì§€
- ì²­í¬ í¬ê¸°: 10
- ì´ë¯¸ì§€ë‹¹ ì²˜ë¦¬ ì‹œê°„: 5ì´ˆ
- ì›Œì»¤ ìˆ˜: 4

```
ì²˜ë¦¬ ì‹œê°„ â‰ˆ (1000 / 10) Ã— 5 / 4 = 125ì´ˆ (ì•½ 2ë¶„)
```

## ğŸ” ëª¨ë‹ˆí„°ë§

### ì§„í–‰ ìƒí™© í™•ì¸

```python
# ì‹¤ì‹œê°„ ì§„í–‰ë¥  ì²´í¬
import requests
import time

batch_id = "your-batch-id"

while True:
    response = requests.get(f"http://localhost:8000/pipeline/batch/{batch_id}")
    data = response.json()["data"]

    print(f"ì§„í–‰ë¥ : {data['progress_percentage']:.1f}%")
    print(f"ì™„ë£Œ: {data['completed_images']}/{data['total_images']}")
    print(f"ì‹¤íŒ¨: {data['failed_images']}")

    if data["status"] in ["SUCCESS", "FAILURE"]:
        break

    time.sleep(5)
```

### Celery Flower ëª¨ë‹ˆí„°ë§

```bash
# Flower ì›¹ UI ì‹œì‘
celery -A celery_app flower
```

ë¸Œë¼ìš°ì €ì—ì„œ `http://localhost:5555` ì ‘ì†

## ğŸ› ë¬¸ì œ í•´ê²°

### ë°°ì¹˜ê°€ ì‹œì‘ë˜ì§€ ì•ŠëŠ” ê²½ìš°

1. Celery ì›Œì»¤ ìƒíƒœ í™•ì¸:
```bash
celery -A celery_app inspect active
```

2. Redis ì—°ê²° í™•ì¸:
```bash
redis-cli ping
```

3. DB ì—°ê²° í™•ì¸:
```bash
psql -U your_user -d your_database -c "SELECT 1;"
```

### ì²­í¬ ì²˜ë¦¬ ì‹¤íŒ¨

ê°œë³„ ì²­í¬ ì‹¤íŒ¨ ì‹œ ìë™ìœ¼ë¡œ ì¬ì‹œë„ë©ë‹ˆë‹¤ (ìµœëŒ€ 3íšŒ).
ì‹¤íŒ¨í•œ ì²­í¬ëŠ” `failed_chunks` ì¹´ìš´í„°ì— ë°˜ì˜ë˜ë©°, í•´ë‹¹ ì²­í¬ì˜ ì´ë¯¸ì§€ë“¤ì€ `failed_images`ì— í¬í•¨ë©ë‹ˆë‹¤.

### ë©”ëª¨ë¦¬ ë¶€ì¡±

ì²­í¬ í¬ê¸°ë¥¼ ì¤„ì´ê±°ë‚˜ ì›Œì»¤ì˜ ë©”ëª¨ë¦¬ë¥¼ ì¦ê°€ì‹œí‚¤ì„¸ìš”:

```bash
# ì²­í¬ í¬ê¸° ê°ì†Œ
chunk_size=5

# ë˜ëŠ” ì›Œì»¤ ë™ì‹œì„± ê°ì†Œ
celery -A celery_app worker --concurrency=2
```

## ğŸ“ˆ í–¥í›„ ê°œì„  ì‚¬í•­

- [ ] ë°°ì¹˜ ìš°ì„ ìˆœìœ„ í
- [ ] ë™ì  ì²­í¬ í¬ê¸° ì¡°ì •
- [ ] ì‹¤íŒ¨í•œ ì´ë¯¸ì§€ë§Œ ì¬ì²˜ë¦¬í•˜ëŠ” ê¸°ëŠ¥
- [ ] ë°°ì¹˜ ì²˜ë¦¬ í†µê³„ ëŒ€ì‹œë³´ë“œ
- [ ] WebSocket ê¸°ë°˜ ì‹¤ì‹œê°„ ì§„í–‰ ìƒí™© ì•Œë¦¼
- [ ] S3/MinIO ì§ì ‘ ì—°ë™

## ğŸ“ API ë¬¸ì„œ

ì „ì²´ API ë¬¸ì„œëŠ” FastAPI Swagger UIì—ì„œ í™•ì¸:
```
http://localhost:8000/docs
```

## ğŸ¤ ê¸°ì—¬

ë²„ê·¸ ë¦¬í¬íŠ¸ë‚˜ ê¸°ëŠ¥ ì œì•ˆì€ ì´ìŠˆë¡œ ë“±ë¡í•´ì£¼ì„¸ìš”.
